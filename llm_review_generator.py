import os
import json
import re
from typing import Dict, List, Any, Optional
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass

# å¯¼å…¥æˆ‘ä»¬çš„æ•°æ®åº“
from database_setup import AcademicPaperDatabase

# æ”¯æŒå¤šç§LLMé€‰æ‹©
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

import numpy as np
from typing import Dict, List, Any
import re
from collections import Counter
import math

class EnhancedSimilarityCalculator:
    def __init__(self, topic: str, subtopics: List[str] = None):
        self.topic = topic.lower()
        self.subtopics = [s.lower() for s in (subtopics or [])]
        
        # æ„å»ºä¸»é¢˜è¯åº“
        self.topic_keywords = self._extract_keywords(topic)
        self.subtopic_keywords = []
        for subtopic in self.subtopics:
            self.subtopic_keywords.extend(self._extract_keywords(subtopic))
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç§»é™¤æ ‡ç‚¹ï¼Œè½¬å°å†™ï¼Œåˆ†è¯
        words = re.findall(r'\b[a-zA-Z]+\b', text.lower())
        # è¿‡æ»¤åœç”¨è¯
        stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had'}
        return [word for word in words if word not in stopwords and len(word) > 2]
    
    def calculate_keyword_similarity(self, content: str) -> float:
        """è®¡ç®—å…³é”®è¯åŒ¹é…ç›¸ä¼¼æ€§"""
        content_lower = content.lower()
        content_keywords = self._extract_keywords(content)
        
        if not content_keywords:
            return 0.0
        
        # 1. ä¸»é¢˜è¯å®Œå…¨åŒ¹é…å¾—åˆ†
        main_topic_matches = 0
        for keyword in self.topic_keywords:
            if keyword in content_lower:
                main_topic_matches += 0.5
        
        main_topic_score = main_topic_matches / len(self.topic_keywords) if self.topic_keywords else 0
        
        # 2. å­ä¸»é¢˜è¯åŒ¹é…å¾—åˆ†
        subtopic_matches = 0
        if self.subtopic_keywords:
            for keyword in self.subtopic_keywords:
                if keyword in content_lower:
                    subtopic_matches += 0.5
            subtopic_score = subtopic_matches / len(self.subtopic_keywords)
        else:
            subtopic_score = 0
        
        
        # 4. TF-IDFé£æ ¼çš„è¯é¢‘å¾—åˆ†
        content_counter = Counter(content_keywords)
        tf_score = 0
        for keyword in self.topic_keywords:
            if keyword in content_counter:
                tf = content_counter[keyword] / len(content_keywords)
                tf_score += tf
        
        tf_score = min(tf_score, 1.0)
        
        # ç»¼åˆå¾—åˆ†
        final_score = (
            0.5 * main_topic_score +      # ä¸»é¢˜è¯åŒ¹é…æœ€é‡è¦
            0.3 * subtopic_score +        # å­ä¸»é¢˜è¯æ¬¡ä¹‹
            0.2 * tf_score               # è¯é¢‘å¾—åˆ†
        )
        
        return min(final_score, 1.0)
    
    def calculate_position_bonus(self, metadata: Dict) -> float:
        """æ ¹æ®å†…å®¹åœ¨è®ºæ–‡ä¸­çš„ä½ç½®ç»™äºˆå¥–åŠ±åˆ†æ•°"""
        content_type = metadata.get('content_type', '')
        
        # ä¸åŒç±»å‹å†…å®¹çš„é‡è¦æ€§æƒé‡
        type_weights = {
            'text': 1.0,
            'equation': 1.05,    # å…¬å¼é€šå¸¸å¾ˆé‡è¦
            'image': 1.05,       # å›¾ç‰‡åŒ…å«é‡è¦ä¿¡æ¯
            'table': 1.05        # è¡¨æ ¼é€šå¸¸æ˜¯å…³é”®ç»“æœ
        }
        
        return type_weights.get(content_type, 1.0)
    
    def extract_core_concepts(self, topic: str) -> str:
        """ä»é•¿æ ‡é¢˜ä¸­æå–æ ¸å¿ƒæ¦‚å¿µï¼Œæé«˜å‘é‡ç›¸ä¼¼åº¦è®¡ç®—çš„å‡†ç¡®æ€§"""
        import re
        
        # ğŸ”§æ·»åŠ ç±»å‹æ£€æŸ¥ï¼Œé˜²æ­¢ä¼ å…¥åˆ—è¡¨ç­‰éå­—ç¬¦ä¸²ç±»å‹
        if not isinstance(topic, str):
            if isinstance(topic, list):
                # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ æˆ–è¿æ¥æ‰€æœ‰å…ƒç´ 
                topic = topic[0] if topic else ""
                print(f"âš ï¸ extract_core_conceptsæ”¶åˆ°åˆ—è¡¨å‚æ•°ï¼Œå·²è½¬æ¢ä¸ºå­—ç¬¦ä¸²: {topic}")
            else:
                # å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                topic = str(topic)
                print(f"âš ï¸ extract_core_conceptsæ”¶åˆ°éå­—ç¬¦ä¸²å‚æ•°ï¼Œå·²è½¬æ¢: {topic}")
        
        # å®šä¹‰åœç”¨è¯ï¼ˆä»‹è¯ã€è¿è¯ã€å¸¸è§ä¿®é¥°è¯ç­‰ï¼‰
        stop_words = {
            'and', 'or', 'for', 'in', 'on', 'at', 'to', 'from', 'with', 'by', 'of', 'the', 'a', 'an',
            'advanced', 'comprehensive', 'detailed', 'systematic', 'efficient', 'effective', 'novel',
            'improved', 'enhanced', 'optimized', 'based', 'using', 'through', 'via', 'approaches',
            'methods', 'techniques', 'applications', 'systems', 'frameworks', 'models', 'analysis'
        }
        
        # 1. åŸºç¡€æ¸…ç†ï¼šç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œè½¬ä¸ºå°å†™ï¼Œåˆ†è¯
        words = re.findall(r'\b[a-zA-Z]+\b', topic.lower())
        
        # 2. ç§»é™¤åœç”¨è¯
        filtered_words = [word for word in words if word not in stop_words and len(word) > 2]
        
        # 3. ä¿ç•™é‡è¦çš„ä¸“ä¸šæœ¯è¯­å’Œæ ¸å¿ƒæ¦‚å¿µï¼ˆä¼˜å…ˆä¿ç•™è¾ƒé•¿çš„è¯æ±‡ï¼‰
        important_words = []
        for word in filtered_words:
            # ä¼˜å…ˆä¿ç•™é•¿è¯æ±‡ï¼ˆé€šå¸¸æ˜¯ä¸“ä¸šæœ¯è¯­ï¼‰
            if len(word) >= 6:
                important_words.append(word)
            # ä¿ç•™ä¸€äº›é‡è¦çš„çŸ­è¯æ±‡
            elif word in ['nlp', 'llm', 'ai', 'ml', 'gpu', 'cpu', 'api', 'gpt', 'bert']:
                important_words.append(word)
        
        # 4. å¦‚æœç­›é€‰åçš„è¯å¤ªå°‘ï¼Œä¿ç•™ä¸€äº›ä¸­ç­‰é•¿åº¦çš„è¯
        if len(important_words) < 3:
            for word in filtered_words:
                if len(word) >= 4 and word not in important_words:
                    important_words.append(word)
                if len(important_words) >= 5:  # é™åˆ¶æ ¸å¿ƒæ¦‚å¿µæ•°é‡
                    break
        
        # 5. ä¿ç•™å‰5ä¸ªæœ€é‡è¦çš„æ¦‚å¿µ
        core_concepts = ' '.join(important_words[:5])
        
        return core_concepts if core_concepts else topic  # å¦‚æœæå–å¤±è´¥ï¼Œè¿”å›åŸæ ‡é¢˜
    
    def multi_level_similarity(self, search_result: Dict, full_topic: str, core_concepts: str) -> float:
        """å¤šå±‚æ¬¡ç›¸ä¼¼åº¦è®¡ç®—ï¼Œæ ¹æ®æ ‡é¢˜é•¿åº¦åŠ¨æ€è°ƒæ•´è®¡ç®—ç­–ç•¥"""
        document_content = search_result.get('document', '')
        metadata = search_result.get('metadata', {})
        
        # 1. è®¡ç®—åŸºäºæ ¸å¿ƒæ¦‚å¿µçš„ç›¸ä¼¼åº¦
        core_vector_sim = 1 - search_result.get('distance', 1.0)  # åŸå§‹å‘é‡ç›¸ä¼¼åº¦
        core_keyword_sim = self._calculate_text_keyword_similarity(document_content, core_concepts)
        
        # 2. è®¡ç®—åŸºäºå®Œæ•´æ ‡é¢˜çš„å…³é”®è¯åŒ¹é…
        full_keyword_sim = self.calculate_keyword_similarity(document_content)
        
        # 3. å…¶ä»–ç»´åº¦ä¿æŒä¸å˜
        position_bonus = self.calculate_position_bonus(metadata)
        content_length = len(document_content)
        length_factor = min(math.log(content_length + 1) / math.log(1000), 1.5)
        
        # è®ºæ–‡ç›¸å…³æ€§
        paper_name = metadata.get('paper_name', '').lower()
        paper_relevance = 1.0
        for keyword in self.topic_keywords:
            if keyword in paper_name:
                paper_relevance += 0.02
        paper_relevance = min(paper_relevance, 1.5)
        
        # 4. æ ¹æ®æ ‡é¢˜é•¿åº¦åŠ¨æ€è°ƒæ•´æƒé‡
        title_length = len(full_topic.split())
        
        if title_length > 8:  # é•¿æ ‡é¢˜
            # æé«˜æ ¸å¿ƒæ¦‚å¿µç›¸ä¼¼åº¦æƒé‡ï¼Œé™ä½å®Œæ•´æ ‡é¢˜æƒé‡
            enhanced_similarity = (
                0.6 * core_vector_sim +         # æ ¸å¿ƒæ¦‚å¿µå‘é‡ç›¸ä¼¼åº¦60%
                0.2 * core_keyword_sim +        # æ ¸å¿ƒæ¦‚å¿µå…³é”®è¯åŒ¹é…20%
                0.1 * full_keyword_sim +        # å®Œæ•´å…³é”®è¯åŒ¹é…10%
                0.1 * (position_bonus - 1.0)    # ä½ç½®åŠ æˆ10%
            ) * length_factor * paper_relevance
        else:  # æ­£å¸¸é•¿åº¦æ ‡é¢˜
            # ä½¿ç”¨åŸå§‹æƒé‡åˆ†é…
            enhanced_similarity = (
                0.7 * core_vector_sim +         # å‘é‡ç›¸ä¼¼åº¦70%
                0.1 * core_keyword_sim +        # æ ¸å¿ƒæ¦‚å¿µåŒ¹é…10%
                0.1 * full_keyword_sim +        # å®Œæ•´å…³é”®è¯åŒ¹é…10%
                0.1 * (position_bonus - 1.0)    # ä½ç½®åŠ æˆ10%
            ) * length_factor * paper_relevance
        
        return min(enhanced_similarity, 1.0)
    
    def _calculate_text_keyword_similarity(self, document_content: str, concepts_text: str) -> float:
        """è®¡ç®—æ–‡æ¡£å†…å®¹ä¸æ ¸å¿ƒæ¦‚å¿µçš„å…³é”®è¯åŒ¹é…ç›¸ä¼¼åº¦"""
        if not concepts_text or not document_content:
            return 0.0
        
        concepts_words = set(concepts_text.lower().split())
        doc_words = set(document_content.lower().split())
        
        # è®¡ç®—äº¤é›†æ¯”ä¾‹
        if not concepts_words:
            return 0.0
        
        intersection = concepts_words.intersection(doc_words)
        similarity = len(intersection) / len(concepts_words)
        
        return similarity
    
    def calculate_enhanced_similarity(self, search_result: Dict, topic: str) -> float:
        """è®¡ç®—å¢å¼ºçš„ç›¸ä¼¼æ€§å¾—åˆ† - ğŸ”§æ”¹è¿›ï¼šä½¿ç”¨å¤šå±‚æ¬¡ç›¸ä¼¼åº¦è®¡ç®—"""
        document_content = search_result.get('document', '')
        metadata = search_result.get('metadata', {})
        content_type = metadata.get('content_type', '')

        # å¯¹äºæ–‡æœ¬å†…å®¹ï¼Œè¿›è¡Œå¤šé‡æ£€æŸ¥
        if content_type == 'text':
            # 1. é•¿åº¦æ£€æŸ¥
            if len(document_content) < 100:
                return 0.0
            
            # 2. å†…å®¹è´¨é‡æ£€æŸ¥ï¼šè¿‡æ»¤æ‰æ•°å­—å æ¯”è¿‡é«˜çš„å†…å®¹
            total_len = len(document_content)
            if total_len > 0:
                digit_count = sum(c.isdigit() for c in document_content)
                if (digit_count / total_len) > 0.8:
                    return 0.0  # æ•°å­—å æ¯”è¶…è¿‡80%ï¼Œåˆ¤å®šä¸ºæ— æ„ä¹‰å†…å®¹

        # ğŸ”§æ”¹è¿›ï¼šä½¿ç”¨å¤šå±‚æ¬¡ç›¸ä¼¼åº¦è®¡ç®—æ¥å¤„ç†é•¿æ ‡é¢˜é—®é¢˜
        # 1. æå–æ ¸å¿ƒæ¦‚å¿µ
        core_concepts = self.extract_core_concepts(topic)
        
        # 2. ä½¿ç”¨å¤šå±‚æ¬¡ç›¸ä¼¼åº¦è®¡ç®—
        enhanced_similarity = self.multi_level_similarity(search_result, topic, core_concepts)
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        if len(topic.split()) > 8:  # é•¿æ ‡é¢˜æ—¶è¾“å‡ºè°ƒè¯•ä¿¡æ¯
            import logging
            logger = logging.getLogger(__name__)
            logger.debug(f"é•¿æ ‡é¢˜å¤„ç†: '{topic}' -> æ ¸å¿ƒæ¦‚å¿µ: '{core_concepts}'")
        
        return enhanced_similarity

@dataclass
class ReviewConfig:
    """ç»¼è¿°ç”Ÿæˆé…ç½®"""
    max_context_length: int = 80000  # å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶
    
    # ç§»é™¤ç¡¬ç¼–ç ï¼Œæ”¹ä¸ºå¯é…ç½®çš„é™åˆ¶
    max_texts_per_query: int = 300           # æ¯æ¬¡æŸ¥è¯¢çš„æ–‡æœ¬æ•°é‡
    max_equations_per_query: int = 100       # æ¯æ¬¡æŸ¥è¯¢çš„å…¬å¼æ•°é‡  
    max_figures_per_query: int = 100         # æ¯æ¬¡æŸ¥è¯¢çš„å›¾ç‰‡æ•°é‡
    max_tables_per_query: int = 100          # æ¯æ¬¡æŸ¥è¯¢çš„è¡¨æ ¼æ•°é‡
    
    # æç¤ºè¯ä¸­ä½¿ç”¨çš„æœ€å¤§æ•°é‡ï¼ˆå¯ä»¥è®¾ç½®ä¸ºNoneè¡¨ç¤ºæ— é™åˆ¶ï¼‰
    max_texts_in_prompt: Optional[int] = None     # Noneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰æ£€ç´¢åˆ°çš„å†…å®¹
    max_equations_in_prompt: Optional[int] = None
    max_figures_in_prompt: Optional[int] = None  
    max_tables_in_prompt: Optional[int] = None
    
    min_relevance_score: float = 0.1
    include_equations: bool = True
    include_figures: bool = True
    include_tables: bool = True
    output_format: str = "markdown"
    language: str = "chinese"

class LLMReviewGenerator:
    def __init__(self, db: AcademicPaperDatabase, config: ReviewConfig = None):
        self.db = db
        self.config = config or ReviewConfig()
        self.llm_client = None
        self.llm_type = None
        
    def setup_openai(self, api_key: str, base_url: str = None, model: str = "gpt-4o"):
        """è®¾ç½®OpenAI API"""
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAI library not installed. Run: pip install openai")
        
        self.llm_client = openai.OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        self.llm_type = "openai"
        self.model_name = model
        print(f"âœ… OpenAI APIè®¾ç½®æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹: {model}")
    
    def setup_local_model(self, model_name: str = "microsoft/DialoGPT-medium"):
        """è®¾ç½®æœ¬åœ°æ¨¡å‹"""
        if not TRANSFORMERS_AVAILABLE:
            raise ImportError("Transformers library not installed. Run: pip install transformers torch")
        
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(model_name)
        self.llm_type = "local"
        self.model_name = model_name
        print(f"âœ… æœ¬åœ°æ¨¡å‹è®¾ç½®æˆåŠŸ: {model_name}")

    def enhanced_gather_research_context(self, topic: str, subtopics: List[str] = None) -> Dict:
        """ä½¿ç”¨å¢å¼ºç›¸ä¼¼æ€§è®¡ç®—æ”¶é›†ç ”ç©¶ä¸Šä¸‹æ–‡ææ–™"""
        print(f"ğŸ” æ­£åœ¨æ”¶é›†å…³äº'{topic}'çš„ç ”ç©¶ææ–™ï¼ˆä½¿ç”¨å¢å¼ºç›¸ä¼¼æ€§è®¡ç®—ï¼‰...")
        
        # åˆå§‹åŒ–å¢å¼ºç›¸ä¼¼æ€§è®¡ç®—å™¨
        similarity_calculator = EnhancedSimilarityCalculator(topic, subtopics)
        
        context = {
            "main_topic": topic,
            "subtopics": subtopics or [],
            "relevant_content": {
                "texts": [],
                "equations": [],
                "figures": [],
                "tables": []
            },
            "source_papers": {},
            "statistics": {}
        }
        
        # ä¸»é¢˜æœç´¢
        search_queries = [topic]
        if subtopics:
            search_queries.extend(subtopics)
        
        all_results = []
        
        for query in search_queries:
            print(f"ğŸ” æœç´¢: {query}")
            
            # è·å–æ›´å¤šåˆå§‹ç»“æœï¼Œç„¶åç”¨å¢å¼ºç›¸ä¼¼æ€§é‡æ–°æ’åº
            text_results = self.db.search_content(
                query, content_type="texts", 
                n_results=min(self.config.max_texts_per_query * 2, 200)  # è·å–2å€ç»“æœç”¨äºé‡æ’åº
            )
            
            if self.config.include_equations:
                equation_results = self.db.search_content(
                    query, content_type="equations", 
                    n_results=min(self.config.max_equations_per_query * 2, 100)
                )
                all_results.extend(equation_results)
            
            if self.config.include_figures:
                figure_results = self.db.search_content(
                    query, content_type="images", 
                    n_results=min(self.config.max_figures_per_query * 2, 100)
                )
                all_results.extend(figure_results)
            
            if self.config.include_tables:
                table_results = self.db.search_content(
                    query, content_type="tables", 
                    n_results=min(self.config.max_tables_per_query * 2, 60)
                )
                all_results.extend(table_results)
            
            all_results.extend(text_results)
        
        # ===== å…³é”®ï¼šä½¿ç”¨å¢å¼ºç›¸ä¼¼æ€§é‡æ–°è®¡ç®—å’Œæ’åº =====
        enhanced_results = []
        seen_ids = set()
        
        for result in all_results:
            if result['id'] in seen_ids:
                continue
            seen_ids.add(result['id'])
            
            # è®¡ç®—å¢å¼ºç›¸ä¼¼æ€§å¾—åˆ†
            enhanced_score = similarity_calculator.calculate_enhanced_similarity(result, topic)
            
            # åªä¿ç•™è¶…è¿‡é˜ˆå€¼çš„ç»“æœ
            if enhanced_score >= self.config.min_relevance_score:
                result['enhanced_similarity'] = enhanced_score
                enhanced_results.append(result)
        
        # æŒ‰å¢å¼ºç›¸ä¼¼æ€§å¾—åˆ†é‡æ–°æ’åº
        enhanced_results.sort(key=lambda x: x['enhanced_similarity'], reverse=True)
        
        print(f"  ğŸ“Š åŸå§‹ç»“æœ: {len(all_results)}, å¢å¼ºç­›é€‰å: {len(enhanced_results)}")
        
        # æŒ‰å†…å®¹ç±»å‹åˆ†ç»„å¹¶é™åˆ¶æ•°é‡
        content_type_limits = {
            'text': self.config.max_texts_per_query,
            'equation': self.config.max_equations_per_query,
            'image': self.config.max_figures_per_query,
            'table': self.config.max_tables_per_query
        }
        
        content_type_counts = {key: 0 for key in content_type_limits.keys()}
        
        # æŒ‰ç›¸å…³æ€§ç­›é€‰å’Œåˆ†ç»„
        for result in enhanced_results:
            content_type = result['metadata']['content_type']
            
            # æ£€æŸ¥è¯¥ç±»å‹æ˜¯å¦å·²è¾¾åˆ°é™åˆ¶
            if content_type_counts.get(content_type, 0) >= content_type_limits.get(content_type, float('inf')):
                continue
            
            content_type_counts[content_type] += 1
            
            paper_name = result['metadata']['paper_name']
            
            # è®°å½•æ¥æºè®ºæ–‡
            if paper_name not in context["source_papers"]:
                context["source_papers"][paper_name] = {
                    "content_count": 0,
                    "sections": []
                }
            
            context["source_papers"][paper_name]["content_count"] += 1
            
            # åˆ†ç±»å­˜å‚¨å†…å®¹
            content_item = {
                "content": result["document"],
                "paper": paper_name,
                "page": result["metadata"]["page_idx"],
                "relevance_score": result['enhanced_similarity'],  # ä½¿ç”¨å¢å¼ºå¾—åˆ†
                "original_vector_score": 1 - result['distance'],   # ä¿ç•™åŸå§‹å‘é‡å¾—åˆ†ç”¨äºå‚è€ƒ
                "original_data": result["metadata"].get("original_data", "")
            }
            
            if content_type == "text":
                context["relevant_content"]["texts"].append(content_item)
            elif content_type == "equation":
                context["relevant_content"]["equations"].append(content_item)
            elif content_type == "image":
                context["relevant_content"]["figures"].append(content_item)
            elif content_type == "table":
                context["relevant_content"]["tables"].append(content_item)
        
        # ç»Ÿè®¡ä¿¡æ¯
        context["statistics"] = {
            "total_papers": len(context["source_papers"]),
            "total_texts": len(context["relevant_content"]["texts"]),
            "total_equations": len(context["relevant_content"]["equations"]),
            "total_figures": len(context["relevant_content"]["figures"]),
            "total_tables": len(context["relevant_content"]["tables"]),
            "enhancement_info": {
                "original_results": len(all_results),
                "enhanced_filtered": len(enhanced_results),
                "final_selected": sum(len(context["relevant_content"][key]) for key in context["relevant_content"])
            }
        }
        
        print(f"ğŸ“Š å¢å¼ºæ£€ç´¢å®Œæˆ:")
        print(f"  - ç›¸å…³è®ºæ–‡: {context['statistics']['total_papers']} ç¯‡")
        print(f"  - æ–‡æœ¬æ®µè½: {context['statistics']['total_texts']} æ¡")
        print(f"  - æ•°å­¦å…¬å¼: {context['statistics']['total_equations']} æ¡")
        print(f"  - å›¾è¡¨: {context['statistics']['total_figures']} æ¡")
        print(f"  - è¡¨æ ¼: {context['statistics']['total_tables']} æ¡")
        print(f"  - ç­›é€‰æ•ˆæœ: {len(all_results)} -> {len(enhanced_results)} -> {context['statistics']['enhancement_info']['final_selected']}")
        
        return context
    # æ›¿æ¢åŸæ¥çš„ gather_research_context æ–¹æ³•
    def gather_research_context(self, topic: str, subtopics: List[str] = None) -> Dict:
        return self.enhanced_gather_research_context(topic, subtopics)

    def analyze_similarity_distribution(self, topic: str) -> Dict:
        """åˆ†æç›¸ä¼¼æ€§å¾—åˆ†åˆ†å¸ƒï¼Œç”¨äºè°ƒè¯•å’Œä¼˜åŒ–"""
        search_results = self.db.search_content(topic, n_results=100)
        
        similarity_calculator = EnhancedSimilarityCalculator(topic)
        
        vector_scores = []
        enhanced_scores = []
        
        for result in search_results:
            vector_score = 1 - result['distance']
            enhanced_score = similarity_calculator.calculate_enhanced_similarity(result, topic)
            
            vector_scores.append(vector_score)
            enhanced_scores.append(enhanced_score)
        
        return {
            "vector_similarity": {
                "mean": np.mean(vector_scores),
                "std": np.std(vector_scores),
                "min": np.min(vector_scores),
                "max": np.max(vector_scores)
            },
            "enhanced_similarity": {
                "mean": np.mean(enhanced_scores),
                "std": np.std(enhanced_scores),
                "min": np.min(enhanced_scores),
                "max": np.max(enhanced_scores)
            },
            "improvement_ratio": np.mean(enhanced_scores) / np.mean(vector_scores) if np.mean(vector_scores) > 0 else 1.0
        }


    def create_prompt(self, topic: str, context: Dict, section_type: str = "full_review") -> str:
        """åˆ›å»ºLLMæç¤ºè¯"""
        
        if self.config.language == "chinese":
            base_prompt = f"""
è¯·åŸºäºæä¾›çš„å­¦æœ¯æ–‡çŒ®ææ–™ï¼Œæ’°å†™ä¸€ç¯‡å…³äº"{topic}"çš„è¯¦å°½ç»¼è¿°æ–‡ç« ã€‚æˆ‘éœ€è¦ä¸€ç¯‡è‡³å°‘50,000å­—çš„å…¨é¢æ·±å…¥çš„å­¦æœ¯ç»¼è¿°ã€‚

ã€å†™ä½œè¦æ±‚ã€‘
1. æ–‡ç« ç»“æ„å®Œæ•´ï¼Œæ¯ä¸ªç« èŠ‚éœ€è¦è¯¦å°½å±•å¼€ï¼Œä¸å¯æ³›æ³›è€Œè°ˆ
2. å‡†ç¡®å¼•ç”¨ç›¸å…³æ–‡çŒ®ï¼Œæ ‡æ³¨æ¥æºè®ºæ–‡å’Œé¡µç ï¼Œé‡‡ç”¨(ä½œè€…ï¼Œå¹´ä»½ï¼Œé¡µç )çš„æ ¼å¼
3. è¯¦ç»†è§£é‡Šæ‰€æœ‰æ¦‚å¿µã€æ–¹æ³•å’ŒæŠ€æœ¯ï¼Œç¡®ä¿ä¸“ä¸šæ€§å’Œå­¦æœ¯æ€§
4. æ°å½“å¼•å…¥æ•°å­¦å…¬å¼ã€å›¾è¡¨å’Œè¡¨æ ¼ï¼Œå¹¶æä¾›è¯¦ç»†è§£é‡Š
5. è¯­è¨€å­¦æœ¯è§„èŒƒï¼Œé€»è¾‘æ¸…æ™°ï¼Œæ®µè½ä¹‹é—´è¿‡æ¸¡è‡ªç„¶
6. çªå‡ºå…³é”®æŠ€æœ¯ç‚¹å’Œåˆ›æ–°ç‚¹ï¼Œè¿›è¡Œæ·±å…¥åˆ†æå’Œæ¯”è¾ƒ
7. æ¯ä¸ªå°èŠ‚è‡³å°‘2000å­—ï¼Œä¸»è¦ç« èŠ‚è‡³å°‘5000å­—

ã€å†…å®¹æ·±åº¦è¦æ±‚ã€‘
1. å¯¹æ¯ä¸ªå…³é”®æ¦‚å¿µè¿›è¡Œå¤šè§’åº¦ã€å¤šå±‚æ¬¡åˆ†æ
2. å¯¹ç›¸å…³ç†è®ºå’Œæ–¹æ³•è¿›è¡Œç³»ç»Ÿæ€§æ¯”è¾ƒ
3. è¯¦ç»†æ¢è®¨æ¯ä¸ªæ–¹æ³•çš„ä¼˜ç¼ºç‚¹ã€é€‚ç”¨æ¡ä»¶å’Œå±€é™æ€§
4. è®¨è®ºç ”ç©¶ç°çŠ¶ã€æŒ‘æˆ˜å’Œæœªæ¥å‘å±•æ–¹å‘
5. å¯¹é‡è¦è§‚ç‚¹è¿›è¡Œæ‰¹åˆ¤æ€§åˆ†æå’Œè¯„ä»·

ã€ç ”ç©¶ææ–™ç»Ÿè®¡ã€‘
- æ¶‰åŠè®ºæ–‡: {context['statistics']['total_papers']} ç¯‡
- æ–‡æœ¬å†…å®¹: {context['statistics']['total_texts']} æ¡
- æ•°å­¦å…¬å¼: {context['statistics']['total_equations']} æ¡
- å›¾è¡¨èµ„æ–™: {context['statistics']['total_figures']} æ¡
- è¡¨æ ¼æ•°æ®: {context['statistics']['total_tables']} æ¡

ã€ä¸»è¦æ¥æºè®ºæ–‡ã€‘
"""
        else:
            base_prompt = f"""
Please write a comprehensive and extensive literature review on "{topic}" based on the provided academic materials. I need an in-depth academic survey of at least 50,000 words.

ã€WRITING REQUIREMENTSã€‘
1. Complete article structure with each section thoroughly developed, avoiding superficial treatment
2. Accurate citations with source papers and page numbers using (Author, Year, Page) format
3. Detailed explanation of all concepts, methods, and techniques ensuring professionalism and academic rigor
4. Appropriate inclusion of mathematical formulas, figures, and tables with comprehensive explanations
5. Academic language with clear logic and natural transitions between paragraphs
6. Highlight key technical points and innovations with in-depth analysis and comparison
7. Each subsection should be at least 2,000 words, main sections at least 5,000 words

ã€DEPTH REQUIREMENTSã€‘
1. Multi-perspective, multi-level analysis of each key concept
2. Systematic comparison of related theories and methods
3. Detailed discussion of advantages, disadvantages, applicable conditions, and limitations of each method
4. Discussion of research status, challenges, and future development directions
5. Critical analysis and evaluation of important viewpoints

ã€Research materials statisticsã€‘
- Papers involved: {context['statistics']['total_papers']}
- Text content: {context['statistics']['total_texts']} items
- Mathematical formulas: {context['statistics']['total_equations']} items
- Figures: {context['statistics']['total_figures']} items
- Tables: {context['statistics']['total_tables']} items

ã€Main source papersã€‘
"""
        
        # æ·»åŠ è®ºæ–‡åˆ—è¡¨
        for i, (paper_name, info) in enumerate(context["source_papers"].items(), 1):
            base_prompt += f"\n{i}. {paper_name} ({info['content_count']} æ¡ç›¸å…³å†…å®¹)"
        
        # ================= å¢å¼ºçš„ç»¼è¿°ç»“æ„å¤§çº² =================
        if self.config.language == "chinese":
            outline_text = """
\n\nã€ç»¼è¿°è¯¦ç»†ç»“æ„å¤§çº²ã€‘è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¯¦ç»†æ’°å†™ç»¼è¿°ï¼Œç¡®ä¿æ¯ä¸ªç« èŠ‚å†…å®¹ä¸°å¯Œã€æ·±å…¥ä¸”å…¨é¢ï¼š

1. å¼•è¨€ï¼ˆ5000å­—ä»¥ä¸Šï¼‰
   1.1 ç ”ç©¶èƒŒæ™¯ä¸æ„ä¹‰
   1.2 ç ”ç©¶é—®é¢˜ä¸æŒ‘æˆ˜
   1.3 ç ”ç©¶ç°çŠ¶æ¦‚è¿°
   1.4 æœ¬ç»¼è¿°çš„ç»„ç»‡ç»“æ„

2. æŠ€æœ¯åŸºç¡€ä¸æ ¸å¿ƒæ¦‚å¿µï¼ˆ8000å­—ä»¥ä¸Šï¼‰
   2.1 å…³é”®æŠ€æœ¯åŸç†è¯¦è§£
   2.2 ç®—æ³•æ¡†æ¶ä¸æ•°å­¦åŸºç¡€
   2.3 è¯„ä¼°æ–¹æ³•ä¸æŒ‡æ ‡
   2.4 æŠ€æœ¯æ¼”è¿›å†ç¨‹

3. ç ”ç©¶æ–¹æ³•ä¸æ¨¡å‹ï¼ˆ10000å­—ä»¥ä¸Šï¼‰
   3.1 ä¸»æµæ¨¡å‹æ¶æ„è¯¦è§£
   3.2 è®­ç»ƒæ–¹æ³•ä¸ä¼˜åŒ–ç­–ç•¥
   3.3 æ¨ç†æŠ€æœ¯ä¸åŠ é€Ÿæ–¹æ³•
   3.4 æ¨¡å‹è¯„ä¼°ä¸æ¯”è¾ƒ

4. åº”ç”¨é¢†åŸŸä¸æ¡ˆä¾‹åˆ†æï¼ˆ10000å­—ä»¥ä¸Šï¼‰
   4.1 å…¸å‹åº”ç”¨åœºæ™¯è¯¦è§£
   4.2 å®é™…è½åœ°æ¡ˆä¾‹ç ”ç©¶
   4.3 æ€§èƒ½è¡¨ç°ä¸æ•ˆæœè¯„ä¼°
   4.4 åº”ç”¨æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ

5. å‰æ²¿è¿›å±•ä¸åˆ›æ–°ç‚¹ï¼ˆ8000å­—ä»¥ä¸Šï¼‰
   5.1 æœ€æ–°ç ”ç©¶çªç ´
   5.2 åˆ›æ–°æŠ€æœ¯ä¸æ–¹æ³•
   5.3 ç†è®ºä¸å®è·µåˆ›æ–°
   5.4 é‡è¦å‘ç°ä¸è´¡çŒ®

6. æŒ‘æˆ˜ä¸æœªè§£å†³é—®é¢˜ï¼ˆ5000å­—ä»¥ä¸Šï¼‰
   6.1 æŠ€æœ¯ç“¶é¢ˆåˆ†æ
   6.2 å¼€æ”¾æ€§é—®é¢˜è®¨è®º
   6.3 äº‰è®®é—®é¢˜ä¸ä¸åŒè§‚ç‚¹
   6.4 ç†è®ºä¸å®è·µå·®è·

7. æœªæ¥ç ”ç©¶æ–¹å‘ï¼ˆ5000å­—ä»¥ä¸Šï¼‰
   7.1 æ½œåœ¨ç ”ç©¶æ–¹å‘
   7.2 æŠ€æœ¯å‘å±•è¶‹åŠ¿é¢„æµ‹
   7.3 è·¨é¢†åŸŸèåˆæœºä¼š
   7.4 é•¿æœŸç ”ç©¶æ„¿æ™¯

8. ç»“è®ºï¼ˆ3000å­—ä»¥ä¸Šï¼‰
   8.1 ç ”ç©¶æ€»ç»“ä¸è´¡çŒ®
   8.2 æ–¹æ³•è®ºåæ€
   8.3 å±€é™æ€§è®¨è®º
   8.4 å®è·µå»ºè®®ä¸å±•æœ›
"""
        else:
            outline_text = """
\n\nã€DETAILED REVIEW STRUCTUREã€‘Please follow this comprehensive structure to write a thorough, in-depth and complete survey:

1. Introduction (5,000+ words)
   1.1 Research Background and Significance
   1.2 Research Questions and Challenges
   1.3 Overview of Current Research Status
   1.4 Organization of this Review

2. Technical Foundations and Core Concepts (8,000+ words)
   2.1 Detailed Explanation of Key Technical Principles
   2.2 Algorithm Frameworks and Mathematical Foundations
   2.3 Evaluation Methods and Metrics
   2.4 Technical Evolution Process

3. Research Methods and Models (10,000+ words)
   3.1 Detailed Analysis of Mainstream Model Architectures
   3.2 Training Methods and Optimization Strategies
   3.3 Inference Techniques and Acceleration Methods
   3.4 Model Evaluation and Comparison

4. Application Domains and Case Studies (10,000+ words)
   4.1 Detailed Explanation of Typical Application Scenarios
   4.2 Real-world Implementation Case Studies
   4.3 Performance and Effectiveness Evaluation
   4.4 Application Challenges and Solutions

5. Frontier Advances and Innovations (8,000+ words)
   5.1 Latest Research Breakthroughs
   5.2 Innovative Technologies and Methods
   5.3 Theoretical and Practical Innovations
   5.4 Important Findings and Contributions

6. Challenges and Unsolved Problems (5,000+ words)
   6.1 Technical Bottleneck Analysis
   6.2 Discussion of Open Problems
   6.3 Controversial Issues and Different Perspectives
   6.4 Gaps Between Theory and Practice

7. Future Research Directions (5,000+ words)
   7.1 Potential Research Directions
   7.2 Predicted Technology Development Trends
   7.3 Cross-domain Integration Opportunities
   7.4 Long-term Research Vision

8. Conclusion (3,000+ words)
   8.1 Research Summary and Contributions
   8.2 Methodological Reflections
   8.3 Limitations Discussion
   8.4 Practical Recommendations and Outlook
"""
        base_prompt += outline_text
        # =====================================================
        
        # æ·»åŠ å†…å®¹åˆ©ç”¨æŒ‡å¯¼
        if self.config.language == "chinese":
            content_guidance = """
\n\nã€å†…å®¹åˆ©ç”¨æŒ‡å¯¼ã€‘
1. æ·±å…¥åˆ†ææä¾›çš„å­¦æœ¯ææ–™ï¼Œæå–å…³é”®ä¿¡æ¯å’Œè§è§£
2. å¯¹æ¯ç¯‡é‡è¦è®ºæ–‡çš„è´¡çŒ®ã€æ–¹æ³•å’Œç»“æœè¿›è¡Œè¯¦ç»†è®¨è®º
3. å°†ä¸åŒè®ºæ–‡çš„è§‚ç‚¹å’Œå‘ç°è¿›è¡Œå¯¹æ¯”å’Œæ•´åˆ
4. å¯¹è®ºæ–‡ä¸­çš„æ•°å­¦å…¬å¼è¿›è¡Œè¯¦ç»†è§£é‡Šå’Œåˆ†æ
5. é’ˆå¯¹å›¾è¡¨å’Œè¡¨æ ¼è¿›è¡Œæ·±åº¦è§£è¯»ï¼Œä¸ä»…æè¿°å…¶å†…å®¹ï¼Œè¿˜è¦åˆ†æå…¶æ„ä¹‰å’Œå½±å“
6. ç¡®ä¿åœ¨ç»¼è¿°ä¸­å…¨é¢åˆ©ç”¨æä¾›çš„ææ–™ï¼Œä¸é—æ¼é‡è¦å†…å®¹
7. å¯¹äºæ¯ä¸ªå…³é”®æ¦‚å¿µï¼Œè‡³å°‘å¼•ç”¨3-5ç¯‡ä¸åŒæ¥æºçš„æ–‡çŒ®è¿›è¡Œè®ºè¿°
8. å¯¹äºäº‰è®®æ€§é—®é¢˜ï¼Œå‘ˆç°ä¸åŒè®ºæ–‡çš„ä¸åŒè§‚ç‚¹
"""
        else:
            content_guidance = """
\n\nã€CONTENT UTILIZATION GUIDANCEã€‘
1. Analyze the provided academic materials in depth to extract key information and insights
2. Discuss the contributions, methods, and results of each important paper in detail
3. Compare and integrate viewpoints and findings from different papers
4. Provide detailed explanations and analyses of mathematical formulas
5. Offer in-depth interpretations of figures and tables, not only describing their content but also analyzing their significance and impact
6. Ensure comprehensive utilization of provided materials in the review, without omitting important content
7. For each key concept, cite at least 3-5 different source papers for discussion
8. For controversial issues, present different perspectives from different papers
"""
        base_prompt += content_guidance
        
        # åŠ¨æ€ç¡®å®šä½¿ç”¨çš„å†…å®¹æ•°é‡
        max_texts = (self.config.max_texts_in_prompt or 
                    len(context["relevant_content"]["texts"]))
        max_equations = (self.config.max_equations_in_prompt or 
                        len(context["relevant_content"]["equations"]))
        max_figures = (self.config.max_figures_in_prompt or 
                    len(context["relevant_content"]["figures"]))
        max_tables = (self.config.max_tables_in_prompt or 
                    len(context["relevant_content"]["tables"]))
        
        # æ·»åŠ ä¸»è¦æ–‡æœ¬å†…å®¹ - ä½¿ç”¨åŠ¨æ€æ•°é‡
        base_prompt += "\n\n=== ä¸»è¦æ–‡æœ¬å†…å®¹ ===\n"
        texts_to_use = context["relevant_content"]["texts"][:max_texts]
        for i, text_item in enumerate(texts_to_use, 1):
            base_prompt += f"\n[æ–‡æœ¬{i}] æ¥æº: {text_item['paper']} (ç¬¬{text_item['page']}é¡µ)\n"
            base_prompt += f"å†…å®¹: {text_item['content'][:1000]}...\n"  # å¢åŠ å†…å®¹é•¿åº¦ä»¥æä¾›æ›´å¤šä¸Šä¸‹æ–‡
        
        # æ·»åŠ å…¬å¼å†…å®¹ - ä½¿ç”¨åŠ¨æ€æ•°é‡
        if context["relevant_content"]["equations"]:
            base_prompt += "\n\n=== ç›¸å…³æ•°å­¦å…¬å¼ ===\n"
            equations_to_use = context["relevant_content"]["equations"][:max_equations]
            for i, eq_item in enumerate(equations_to_use, 1):
                base_prompt += f"\n[å…¬å¼{i}] æ¥æº: {eq_item['paper']} (ç¬¬{eq_item['page']}é¡µ)\n"
                base_prompt += f"å†…å®¹: {eq_item['content']}\n"
                base_prompt += f"åŸå§‹æ•°æ®: {eq_item['original_data'][:200]}...\n"  # æ·»åŠ åŸå§‹æ•°æ®ä»¥å¸®åŠ©ç†è§£å…¬å¼
        
        # æ·»åŠ å›¾è¡¨å†…å®¹ - ä½¿ç”¨åŠ¨æ€æ•°é‡
        if context["relevant_content"]["figures"]:
            base_prompt += "\n\n=== ç›¸å…³å›¾è¡¨ ===\n"
            figures_to_use = context["relevant_content"]["figures"][:max_figures]
            for i, fig_item in enumerate(figures_to_use, 1):
                base_prompt += f"\n[å›¾è¡¨{i}] æ¥æº: {fig_item['paper']} (ç¬¬{fig_item['page']}é¡µ)\n"
                base_prompt += f"æè¿°: {fig_item['content']}\n"
                base_prompt += f"åŸå§‹æ•°æ®: {fig_item['original_data'][:200]}...\n"  # æ·»åŠ åŸå§‹æ•°æ®ä»¥å¸®åŠ©ç†è§£å›¾è¡¨
        
        # æ·»åŠ è¡¨æ ¼å†…å®¹ - ä½¿ç”¨åŠ¨æ€æ•°é‡
        if context["relevant_content"]["tables"]:
            base_prompt += "\n\n=== ç›¸å…³è¡¨æ ¼ ===\n"
            tables_to_use = context["relevant_content"]["tables"][:max_tables]
            for i, table_item in enumerate(tables_to_use, 1):
                base_prompt += f"\n[è¡¨æ ¼{i}] æ¥æº: {table_item['paper']} (ç¬¬{table_item['page']}é¡µ)\n"
                base_prompt += f"å†…å®¹: {table_item['content'][:500]}...\n"  # å¢åŠ å†…å®¹é•¿åº¦
                base_prompt += f"åŸå§‹æ•°æ®: {table_item['original_data'][:200]}...\n"  # æ·»åŠ åŸå§‹æ•°æ®ä»¥å¸®åŠ©ç†è§£è¡¨æ ¼
        
        # æ·»åŠ å†™ä½œæŒ‡å¯¼å’Œè¾“å‡ºæ ¼å¼è¦æ±‚
        if self.config.language == "chinese":
            writing_guide = """
\n\nã€å†™ä½œé£æ ¼ä¸è¾“å‡ºè¦æ±‚ã€‘
1. æ’°å†™é•¿åº¦è¦æ±‚ï¼šæ€»è®¡50,000å­—ä»¥ä¸Šï¼Œæ¯ä¸ªä¸»è¦ç« èŠ‚è‡³å°‘5,000å­—
2. å†™ä½œé£æ ¼ï¼šå­¦æœ¯ä¸¥è°¨ã€é€»è¾‘æ¸…æ™°ã€å†…å®¹æ·±å…¥ã€åˆ†æé€å½»
3. å¼•ç”¨æ ¼å¼ï¼šä½¿ç”¨(ä½œè€…ï¼Œå¹´ä»½ï¼Œé¡µç )æ ¼å¼è¿›è¡Œå‡†ç¡®å¼•ç”¨
4. å…¬å¼å¤„ç†ï¼šä½¿ç”¨LaTeXè¯­æ³•æ­£ç¡®å‘ˆç°æ‰€æœ‰æ•°å­¦å…¬å¼
5. å›¾è¡¨å¼•ç”¨ï¼šè¯¦ç»†æè¿°å›¾è¡¨å†…å®¹å¹¶åˆ†æå…¶æ„ä¹‰ï¼Œä½¿ç”¨![å›¾X](å›¾ç‰‡è·¯å¾„)æ ¼å¼å¼•ç”¨å›¾ç‰‡
6. è¡¨æ ¼å¤„ç†ï¼šä½¿ç”¨markdownè¡¨æ ¼è¯­æ³•æ­£ç¡®å‘ˆç°è¡¨æ ¼å†…å®¹
7. ç« èŠ‚ç»„ç»‡ï¼šæ¯ä¸ªç« èŠ‚å¼€å§‹å‰æä¾›ç®€çŸ­æ¦‚è¿°ï¼Œç« èŠ‚ç»“æŸæä¾›å°ç»“
8. é€»è¾‘è¿è´¯ï¼šç¡®ä¿ç« èŠ‚é—´ã€æ®µè½é—´é€»è¾‘æµç•…ï¼Œä½¿ç”¨é€‚å½“çš„è¿‡æ¸¡è¯

è¯·ç¡®ä¿å†…å®¹è¯¦å°½ã€å­¦æœ¯æ€§å¼ºã€å¼•ç”¨å……åˆ†ï¼Œä¸è¦æ³›æ³›è€Œè°ˆã€‚å¯¹äºæ¯ä¸ªé‡è¦æ¦‚å¿µå’Œæ–¹æ³•ï¼Œéƒ½éœ€è¦æ·±å…¥æ¢è®¨å…¶åŸºç¡€åŸç†ã€æŠ€æœ¯ç»†èŠ‚ã€åº”ç”¨åœºæ™¯å’Œå‘å±•è¶‹åŠ¿ã€‚ä¸è¦ç®€å•ç½—åˆ—å’Œå †ç Œä¿¡æ¯ï¼Œè€Œè¦è¿›è¡Œæ·±åº¦åˆ†æå’Œæ‰¹åˆ¤æ€§æ€è€ƒã€‚æœ€ç»ˆäº¤ä»˜çš„ç»¼è¿°åº”å½“æ˜¯è¯¥é¢†åŸŸæœ€å…¨é¢ã€æœ€æ·±å…¥ã€æœ€æƒå¨çš„å­¦æœ¯æ–‡çŒ®ä¹‹ä¸€ã€‚
"""
        else:
            writing_guide = """
\n\nã€WRITING STYLE AND OUTPUT REQUIREMENTSã€‘
1. Length requirement: Total of 50,000+ words, with each main section at least 5,000 words
2. Writing style: Academically rigorous, logically clear, in-depth content, thorough analysis
3. Citation format: Use (Author, Year, Page) format for accurate citations
4. Formula processing: Correctly present all mathematical formulas using LaTeX syntax
5. Figure references: Describe figure content in detail and analyze its significance, use ![Figure X](image path) format
6. Table processing: Correctly present table content using markdown table syntax
7. Section organization: Provide brief overview before each section begins, provide summary at end of section
8. Logical coherence: Ensure smooth logic between sections and paragraphs, use appropriate transition words

Please ensure the content is extensive, highly academic, well-cited, and not superficial. Each important concept and method needs in-depth discussion of its fundamental principles, technical details, application scenarios, and development trends. Don't simply list and pile up information, but engage in deep analysis and critical thinking. The final delivered review should be one of the most comprehensive, in-depth, and authoritative academic literature in the field.
"""
        base_prompt += writing_guide
        
        # ä¿®æ”¹è¯­è¨€åˆ¤æ–­é€»è¾‘å¹¶è¡¥å……å­—æ•°è¯´æ˜
        if self.config.language == "chinese":
            base_prompt += "\n\nè¯·åŸºäºä»¥ä¸Šææ–™å’Œç»“æ„æ’°å†™ä¸å°‘äº50000å­—çš„ç»¼è¿°æ–‡ç« ï¼Œç¡®ä¿å¼•ç”¨å‡†ç¡®ï¼Œå†…å®¹å®Œæ•´ï¼Œæ·±åº¦åˆ†æï¼Œå­¦æœ¯ä¸¥è°¨ã€‚æ³¨æ„ï¼šè¿™æ˜¯ä¸€ç¯‡å­¦æœ¯ç»¼è¿°ï¼Œéœ€è¦è¯¦å°½åœ°è¦†ç›–æ‰€æœ‰ç›¸å…³ä¸»é¢˜å’Œæ–‡çŒ®ï¼Œå­—æ•°ä¸è¶³å°†æ— æ³•æ»¡è¶³å­¦æœ¯è¦æ±‚ã€‚"
        else:
            base_prompt += "\n\nPlease write a comprehensive review article based on the above materials and structure, with at least 50,000 words, ensuring accurate citations, complete content, in-depth analysis, and academic rigor. Note: This is an academic review that needs to comprehensively cover all relevant topics and literature; insufficient word count will not meet academic requirements."
        
        return base_prompt
    
    def call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLMç”Ÿæˆå†…å®¹"""
        if self.llm_type == "openai":
            return self._call_openai(prompt)
        elif self.llm_type == "local":
            return self._call_local_model(prompt)
        else:
            raise ValueError("è¯·å…ˆè®¾ç½®LLMï¼ˆsetup_openaiæˆ–setup_local_modelï¼‰")
    
    def _call_openai(self, prompt: str) -> str:
        """è°ƒç”¨OpenAI API"""
        try:
            response = self.llm_client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯ç»¼è¿°å†™ä½œåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå’Œæ•´åˆå­¦æœ¯æ–‡çŒ®ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ›å»ºè¯¦å°½ã€å…¨é¢çš„å­¦æœ¯ç»¼è¿°ï¼Œå†…å®¹å¿…é¡»è¯¦å®ã€æ·±å…¥ã€æœ‰å­¦æœ¯ä»·å€¼ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=32000,  # å¤§å¹…å¢åŠ ä»¤ç‰Œé™åˆ¶
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"âŒ OpenAI APIè°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def _call_local_model(self, prompt: str) -> str:
        """è°ƒç”¨æœ¬åœ°æ¨¡å‹"""
        try:
            inputs = self.tokenizer.encode(prompt, return_tensors="pt", max_length=2048, truncation=True)
            
            with torch.no_grad():
                outputs = self.model.generate(
                    inputs,
                    max_length=inputs.shape[1] + 1000,
                    num_return_sequences=1,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            return response[len(prompt):].strip()
        except Exception as e:
            print(f"âŒ æœ¬åœ°æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def generate_review(self, topic: str, subtopics: List[str] = None, output_file: str = None) -> str:
        """ç”Ÿæˆå®Œæ•´çš„ç»¼è¿°æ–‡ç« """
        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆå…³äº'{topic}'çš„ç»¼è¿°æ–‡ç« ...")
        
        # 1. æ”¶é›†ç ”ç©¶ææ–™
        context = self.gather_research_context(topic, subtopics)
        
        # 2. åˆ›å»ºæç¤ºè¯
        prompt = self.create_prompt(topic, context)
        
        print(f"ğŸ“ æ­£åœ¨è°ƒç”¨{self.llm_type}æ¨¡å‹ç”Ÿæˆç»¼è¿°...")
        
        # 3. è°ƒç”¨LLMç”Ÿæˆ
        review_content = self.call_llm(prompt)
        
        if not review_content:
            print("âŒ ç»¼è¿°ç”Ÿæˆå¤±è´¥")
            return None
        
        # 4. åå¤„ç†å’Œæ ¼å¼åŒ–
        formatted_review = self.format_review(review_content, context, topic)
        
        # 5. ä¿å­˜æ–‡ä»¶
        if output_file:
            self.save_review(formatted_review, output_file, context)
            print(f"âœ… ç»¼è¿°å·²ä¿å­˜åˆ°: {output_file}")
        
        return formatted_review
    
    def format_review(self, review_content: str, context: Dict, topic: str) -> str:
        """æ ¼å¼åŒ–ç»¼è¿°å†…å®¹"""
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        if self.config.output_format == "markdown":
            formatted = f"""# {topic} - ç»¼è¿°

**ç”Ÿæˆæ—¶é—´**: {current_time}
**æ•°æ®æº**: {context['statistics']['total_papers']} ç¯‡å­¦æœ¯è®ºæ–‡
**åŒ…å«å†…å®¹**: {context['statistics']['total_texts']} ä¸ªæ–‡æœ¬æ®µè½, {context['statistics']['total_equations']} ä¸ªå…¬å¼, {context['statistics']['total_figures']} ä¸ªå›¾è¡¨, {context['statistics']['total_tables']} ä¸ªè¡¨æ ¼

## å†…å®¹æè¦

æœ¬ç»¼è¿°åŸºäº {context['statistics']['total_papers']} ç¯‡å­¦æœ¯è®ºæ–‡ï¼Œå…¨é¢æ·±å…¥åœ°åˆ†æäº† {topic} ç›¸å…³çš„ç ”ç©¶ç°çŠ¶ã€æŠ€æœ¯æ–¹æ³•ã€åº”ç”¨åœºæ™¯å’Œæœªæ¥å‘å±•æ–¹å‘ã€‚ç»¼è¿°æ€»é•¿åº¦è¶…è¿‡ 50,000 å­—ï¼Œæ¶µç›–äº†è¯¥é¢†åŸŸçš„æ ¸å¿ƒæ¦‚å¿µã€å…³é”®æŠ€æœ¯å’Œæœ€æ–°è¿›å±•ï¼Œæ˜¯ä¸€ä»½å…¨é¢è€Œæƒå¨çš„å­¦æœ¯å‚è€ƒèµ„æ–™ã€‚

---

{review_content}

---

## å‚è€ƒæ–‡çŒ®

"""
            
            # æ·»åŠ å‚è€ƒæ–‡çŒ®åˆ—è¡¨
            for i, (paper_name, info) in enumerate(context["source_papers"].items(), 1):
                formatted += f"{i}. {paper_name}\n"
            
            formatted += f"\n*æœ¬ç»¼è¿°ç”±AIç³»ç»ŸåŸºäº{len(context['source_papers'])}ç¯‡å­¦æœ¯è®ºæ–‡è‡ªåŠ¨ç”Ÿæˆï¼Œç”Ÿæˆæ—¶é—´ï¼š{current_time}*"
            
            # æ·»åŠ å›¾è¡¨å’Œå…¬å¼å¤„ç†è¯´æ˜
            if context["relevant_content"]["figures"] or context["relevant_content"]["equations"]:
                formatted += "\n\n## é™„å½•ï¼šå›¾è¡¨å’Œå…¬å¼æ¥æº\n\n"
                
                if context["relevant_content"]["figures"]:
                    formatted += "### å›¾è¡¨æ¥æº\n\n"
                    for i, fig_item in enumerate(context["relevant_content"]["figures"][:20], 1):
                        formatted += f"**å›¾{i}**: æ¥æºäºã€Š{fig_item['paper']}ã€‹ç¬¬{fig_item['page']}é¡µ\n\n"
                
                if context["relevant_content"]["equations"]:
                    formatted += "### å…¬å¼æ¥æº\n\n"
                    for i, eq_item in enumerate(context["relevant_content"]["equations"][:20], 1):
                        formatted += f"**å…¬å¼{i}**: æ¥æºäºã€Š{eq_item['paper']}ã€‹ç¬¬{eq_item['page']}é¡µ\n\n"
            
        return formatted
    
    def save_review(self, content: str, output_file: str, context: Dict):
        """ä¿å­˜ç»¼è¿°åˆ°æ–‡ä»¶"""
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        if self.config.output_format == "markdown":
            with open(output_path.with_suffix('.md'), 'w', encoding='utf-8') as f:
                f.write(content)
        
        # åŒæ—¶ä¿å­˜ä¸Šä¸‹æ–‡ä¿¡æ¯
        context_file = output_path.with_suffix('.json')
        with open(context_file, 'w', encoding='utf-8') as f:
            json.dump(context, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ä¸Šä¸‹æ–‡ä¿¡æ¯å·²ä¿å­˜åˆ°: {context_file}")

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºä½¿ç”¨"""
    print("ğŸ”¬ å­¦æœ¯è®ºæ–‡ç»¼è¿°ç”Ÿæˆç³»ç»Ÿ")
    print("=" * 50)
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = AcademicPaperDatabase(db_path="D:/Desktop/ZJU/300/academic_papers_db")
    
    # é…ç½®æ›´å®½æ¾çš„å‚æ•°ä»¥å……åˆ†åˆ©ç”¨å¢å¼ºç›¸ä¼¼æ€§
    config = ReviewConfig(
        max_texts_per_query=500,        # å¢åŠ æœç´¢æ•°é‡
        max_equations_per_query=200,
        max_figures_per_query=200,
        max_tables_per_query=200,
        min_relevance_score=0.10,       # ç¨å¾®é™ä½é˜ˆå€¼ï¼Œè·å–æ›´å¤šå†…å®¹
        max_texts_in_prompt=400,        # å¢åŠ æç¤ºè¯ä¸­åŒ…å«çš„å†…å®¹æ•°é‡
        max_equations_in_prompt=150,
        max_figures_in_prompt=150,
        max_tables_in_prompt=150,
        max_context_length=80000,       # ç¡®ä¿ä¸Šä¸‹æ–‡é•¿åº¦è¶³å¤Ÿå¤§
    )
    
    generator = LLMReviewGenerator(db, config)
    
    # è®¾ç½®LLMï¼ˆè¯·æ ¹æ®æ‚¨çš„æƒ…å†µé€‰æ‹©ï¼‰
    
    # é€‰é¡¹1: ä½¿ç”¨OpenAI API
    try:
        api_key = input("è¯·è¾“å…¥API Key(å¯é€‰ï¼Œå›è½¦ä½¿ç”¨é»˜è®¤Openrouter):").strip()
        api_key=api_key if api_key else "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"
        if api_key:
            base_url = input("è¯·è¾“å…¥API Base URL (å¯é€‰ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤): ").strip()
            model = input("è¯·è¾“å…¥æ¨¡å‹åç§°(å¯é€‰ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤): ").strip()
            generator.setup_openai(
                api_key=api_key,
                # é»˜è®¤ä½¿ç”¨openrouterçš„API
                base_url=base_url if base_url else "https://openrouter.ai/api/v1",
                model=model if model else "anthropic/claude-sonnet-4"
            )
        else:
            raise ValueError("ä½¿ç”¨æœ¬åœ°æ¨¡å‹")
    except:
        # é€‰é¡¹2: ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆå¦‚æœOpenAIä¸å¯ç”¨ï¼‰
        print("âš ï¸ å°†ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆå¯èƒ½æ•ˆæœè¾ƒå·®ï¼‰")
        try:
            generator.setup_local_model("microsoft/DialoGPT-medium")
        except Exception as e:
            print(f"âŒ æœ¬åœ°æ¨¡å‹è®¾ç½®å¤±è´¥: {e}")
            print("è¯·å®‰è£…å¿…è¦ä¾èµ–: pip install transformers torch")
            return
    
    # ç”¨æˆ·è¾“å…¥ä¸»é¢˜
    topic = input("\nè¯·è¾“å…¥ç»¼è¿°ä¸»é¢˜ï¼ˆå¯é€‰ï¼Œå›è½¦ä½¿ç”¨é»˜è®¤LLMï¼‰: ").strip()
    if not topic:
        topic = "Large Language Models"
    
    subtopics_input = input("è¯·è¾“å…¥å­ä¸»é¢˜ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¯é€‰ï¼‰: ").strip()
    subtopics = [s.strip() for s in subtopics_input.split(",")] if subtopics_input else ["transformer architecture", "attention mechanism", "fine-tuning", "RLHF"]
    
    output_file = input("è¯·è¾“å…¥è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼‰: ").strip()
    if not output_file:
        safe_topic = re.sub(r'[^\w\s-]', '', topic)[:50]
        output_file = f"./reviews/{safe_topic}_review"
    
    # ç”Ÿæˆç»¼è¿°
    review = generator.generate_review(
        topic=topic,
        subtopics=subtopics,
        output_file=output_file
    )
    
    if review:
        print("\n" + "=" * 50)
        print("ğŸ“„ ç”Ÿæˆçš„ç»¼è¿°é¢„è§ˆ:")
        print("=" * 50)
        print(review[:1000] + "..." if len(review) > 1000 else review)
    
if __name__ == "__main__":
    main()