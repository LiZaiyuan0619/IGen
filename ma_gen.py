# -*- coding: utf-8 -*-
"""
å­¦æœ¯ç»¼è¿°å¤šæ™ºèƒ½ä½“ç”Ÿæˆç³»ç»Ÿ

è„šæœ¬ç›®æ ‡ä»»åŠ¡ï¼šä½¿ç”¨å¤šæ™ºèƒ½ä½“æ¶æ„è‡ªåŠ¨ç”Ÿæˆå­¦æœ¯ç»¼è¿°

ä¸Šä¸‹æ–‡ï¼š
- åŸºäºChromaDBå‘é‡æ•°æ®åº“ä¸­å·²æœ‰çš„å­¦æœ¯è®ºæ–‡å†…å®¹
- é€šè¿‡å¤šä¸ªä¸“ä¸šæ™ºèƒ½ä½“åä½œå®Œæˆå¤æ‚çš„å­¦æœ¯ç»¼è¿°ç”Ÿæˆä»»åŠ¡
- æ”¯æŒäº¤äº’æ¨¡å¼å’Œå‘½ä»¤è¡Œå‚æ•°æ¨¡å¼ä¸¤ç§è¿è¡Œæ–¹å¼

è¾“å…¥ï¼š
- ç”¨æˆ·æä¾›çš„ä¸»é¢˜å’Œå­ä¸»é¢˜
- APIé…ç½®ï¼ˆå¯†é’¥ã€æ¨¡å‹é€‰æ‹©ç­‰ï¼‰
- å‘é‡æ•°æ®åº“è·¯å¾„å’Œè¾“å‡ºè·¯å¾„

æ‰§è¡Œæ­¥éª¤ï¼š
1. åˆå§‹åŒ–LLMå·¥å‚å’Œæ•°æ®åº“è¿æ¥
2. è§£æå’Œæ ‡å‡†åŒ–ç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜
3. åˆ›å»ºå¹¶åè°ƒå¤šä¸ªæ™ºèƒ½ä½“ï¼ˆè§£é‡Šå™¨ã€è§„åˆ’ã€ä¸°å¯Œã€æ’°å†™ï¼‰
4. æŒ‰é˜¶æ®µç”Ÿæˆç»¼è¿°ï¼ˆå¤§çº²åˆ›å»ºâ†’å¤§çº²ä¸°å¯Œâ†’å†…å®¹æ’°å†™â†’å†…å®¹æ•´åˆï¼‰
5. ä¿å­˜ç»“æœå¹¶è®°å½•ç”Ÿæˆè€—æ—¶

è¾“å‡ºï¼š
- å­¦æœ¯ç»¼è¿°Markdownæ–‡ä»¶
- å…ƒæ•°æ®JSONæ–‡ä»¶
- Wordæ–‡æ¡£ï¼ˆå¦‚æœå¯ç”¨ï¼‰
- ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯å’Œæ€»è€—æ—¶
"""

import os
import json
import asyncio
import argparse
from typing import List, Dict
from datetime import datetime
import traceback
import sys
from pathlib import Path
import re
import time  # æ·»åŠ æ—¶é—´æ¨¡å—ç”¨äºè®¡æ—¶
try:
    from docx import Document
    from docx.shared import Inches, Pt
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    from docx.enum.style import WD_STYLE_TYPE
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    print("âš ï¸ python-docxæœªå®‰è£…ï¼Œæ— æ³•ç”ŸæˆWordæ–‡æ¡£ã€‚å¯ä½¿ç”¨ 'pip install python-docx' å®‰è£…ã€‚")
from multi_agent import (
    EnricherAgent,
    LLMFactory, 
    AcademicPaperDatabase, 
    ModelType,
    AgentConfig,
    PlannerAgent,
    WriterAgent,
    InterpreterAgent
)
from md_to_word_converter import convert_markdown_to_word

class MultiAgentCoordinator:
    """å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåè°ƒå™¨ï¼Œç®¡ç†æ™ºèƒ½ä½“é—´äº¤äº’ä¸ä»»åŠ¡åˆ†é…"""
    
    def __init__(self, llm_factory: LLMFactory, db: AcademicPaperDatabase, config: Dict = None):
        """åˆå§‹åŒ–å¤šæ™ºèƒ½ä½“åè°ƒå™¨"""
        self.llm_factory = llm_factory
        self.db = db
        self.config = config or {}
        self.planner = None
        self.enricher = None
        self.interpreter = None  # ğŸ†• æ·»åŠ è§£é‡Šå™¨æ™ºèƒ½ä½“
        self.writers = {}
        self.topic = ""
        self.subtopics = []
        # ç« èŠ‚å¹¶å‘ä¸Šé™ï¼ˆç« é—´å¹¶å‘ã€ç« å†…é¡ºåºï¼‰ï¼Œé»˜è®¤ 6ï¼Œå¯é€šè¿‡ä¼ å…¥ config['writer_concurrency'] è°ƒæ•´
        self.writer_concurrency = int(self.config.get("writer_concurrency", 6))
        
    async def initialize_agents(self, topic: str, subtopics: List[str] = None):
        """åˆå§‹åŒ–å¹¶é…ç½®æ‰€æœ‰æ™ºèƒ½ä½“"""
        print(f"ğŸš€ åˆå§‹åŒ–æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¸»é¢˜ï¼š'{topic}'")
        self.topic = topic
        self.subtopics = subtopics or []
        
        # åˆ›å»ºè§„åˆ’æ™ºèƒ½ä½“
        planner_config = AgentConfig(
            model_name=self.config.get("planner_model", ModelType.CLAUDE.value),
            temperature=0.7,
            max_tokens=15000,
            role_description="å­¦æœ¯ç»¼è¿°è§„åˆ’ä¸“å®¶",
            system_message="ä½ æ˜¯å­¦æœ¯ç»¼è¿°è§„åˆ’ä¸“å®¶ï¼Œæ“…é•¿ç»„ç»‡å’Œè§„åˆ’å¤æ‚çš„å­¦æœ¯æ–‡çŒ®ç»¼è¿°ç»“æ„ã€‚"
        )
        self.planner = await self.create_planner(planner_config)
        
        # åˆ›å»ºä¸°å¯Œæ™ºèƒ½ä½“
        enricher_config = AgentConfig(
            model_name=self.config.get("enricher_model", ModelType.CLAUDE.value),
            temperature=0.7,
            max_tokens=15000,
            role_description="å­¦æœ¯ç»¼è¿°ç¼–è¾‘ä¸“å®¶",
            system_message="ä½ æ˜¯å­¦æœ¯ç»¼è¿°ç¼–è¾‘ä¸“å®¶ï¼Œæ“…é•¿ä¸°å¯Œå¤§çº²å†…å®¹ï¼Œä¸ºä¸‹æ¸¸LLMæä¾›è¯¦ç»†çš„ç« èŠ‚ç¼–å†™æŒ‡å¼•ã€‚"
        )
        self.enricher = await self.create_enricher(enricher_config)
            
    async def create_planner(self, config: AgentConfig) -> PlannerAgent:
        """åˆ›å»ºè§„åˆ’æ™ºèƒ½ä½“"""
        planner = PlannerAgent(
            name="è§„åˆ’æ™ºèƒ½ä½“",
            config=config,
            llm_factory=self.llm_factory,
            db=self.db
        )
        return planner
    
    async def create_enricher(self, config: AgentConfig) -> EnricherAgent:
        """åˆ›å»ºä¸°å¯Œæ™ºèƒ½ä½“"""
        enricher = EnricherAgent(
            name="ä¸°å¯Œæ™ºèƒ½ä½“",
            config=config,
            llm_factory=self.llm_factory,
            db=self.db
        )
        return enricher
    
    async def create_interpreter(self, config: AgentConfig) -> InterpreterAgent:
        """åˆ›å»ºè§£é‡Šå™¨æ™ºèƒ½ä½“"""
        interpreter = InterpreterAgent(
            name="è§£é‡Šå™¨æ™ºèƒ½ä½“",
            config=config,
            llm_factory=self.llm_factory,
            db=self.db
        )
        return interpreter
    
    async def create_writers(self, outline: Dict, writer_config: AgentConfig) -> Dict[str, WriterAgent]:
        """æ ¹æ®å¤§çº²åˆ›å»ºæ’°å†™æ™ºèƒ½ä½“ï¼Œå¹¶åˆ†é…å¯¹åº”ç« èŠ‚çš„å†…å®¹æŒ‡å¼•"""
        writers = {}
        
        # æ£€æŸ¥outlineç»“æ„ï¼Œç¡®ä¿åªå¤„ç†é¡¶å±‚ç« èŠ‚
        chapters = outline.get("chapters", {})
        
        # å¤„ç†ä¸¤ç§å¯èƒ½çš„æ•°æ®ç»“æ„ï¼šåˆ—è¡¨æˆ–å­—å…¸
        if isinstance(chapters, dict):
            # å¦‚æœchaptersæ˜¯å­—å…¸ï¼Œåˆ™ç›´æ¥ä½¿ç”¨å­—å…¸çš„å€¼
            main_chapters = list(chapters.values())
            print(f"ğŸ” è¯†åˆ«å‡º {len(main_chapters)} ä¸ªä¸€çº§ç« èŠ‚ï¼ˆå­—å…¸æ ¼å¼ï¼‰ï¼Œä¸ºæ¯ä¸ªç« èŠ‚åˆ›å»ºä¸€ä¸ªæ’°å†™æ™ºèƒ½ä½“")
        elif isinstance(chapters, list):
            # å¦‚æœchaptersæ˜¯åˆ—è¡¨ï¼Œç­›é€‰å‡ºçœŸæ­£çš„ä¸€çº§ç« èŠ‚
            main_chapters = [c for c in chapters if c.get("id", "").isdigit() or len(c.get("id", "").split(".")) == 1]
            print(f"ğŸ” è¯†åˆ«å‡º {len(main_chapters)} ä¸ªä¸€çº§ç« èŠ‚ï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰ï¼Œä¸ºæ¯ä¸ªç« èŠ‚åˆ›å»ºä¸€ä¸ªæ’°å†™æ™ºèƒ½ä½“")
        else:
            print("âŒ æ— æ³•è¯†åˆ«ç« èŠ‚æ•°æ®ç»“æ„")
            return {}
        
        for chapter in main_chapters:
            chapter_id = chapter.get("id", "")
            chapter_title = chapter.get("title", "")
            
            # æ”¶é›†ç« èŠ‚çš„å†…å®¹æŒ‡å¼•å’Œå…¶ä»–ä¿¡æ¯
            chapter_guidance = {
                "content_guide": chapter.get("content_guide", ""),
                "keywords": chapter.get("keywords", []),
                "research_focus": chapter.get("research_focus", []),
                "subsections": {}
            }
            
            # æ”¶é›†å­ç« èŠ‚çš„å†…å®¹æŒ‡å¼•
            subsections = chapter.get("subsections", {})
            if isinstance(subsections, dict):
                # å¦‚æœsubsectionsæ˜¯å­—å…¸ï¼Œéå†å…¶å€¼
                for subsection_id, subsection in subsections.items():
                    if subsection_id:
                        chapter_guidance["subsections"][subsection_id] = {
                            "content_guide": subsection.get("content_guide", ""),
                            "key_points": subsection.get("key_points", []),
                            "writing_guide": subsection.get("writing_guide", "")
                        }
            elif isinstance(subsections, list):
                # å¦‚æœsubsectionsæ˜¯åˆ—è¡¨ï¼Œä¿æŒåŸæœ‰é€»è¾‘
                for subsection in subsections:
                    subsection_id = subsection.get("id", "")
                    if subsection_id:
                        chapter_guidance["subsections"][subsection_id] = {
                            "content_guide": subsection.get("content_guide", ""),
                            "key_points": subsection.get("key_points", []),
                            "writing_guide": subsection.get("writing_guide", "")
                        }
            
            # ä¸ºæ¯ä¸ªä¸€çº§ç« èŠ‚åˆ›å»ºä¸€ä¸ªæ’°å†™æ™ºèƒ½ä½“
            writer = WriterAgent(
                name=f"æ’°å†™æ™ºèƒ½ä½“-{chapter_id}",
                config=writer_config,
                llm_factory=self.llm_factory,
                db=self.db,
                section_id=chapter_id,
                section_guidance=chapter_guidance  # ä¼ é€’ç« èŠ‚æŒ‡å¼•
            )
            writers[chapter_id] = writer
            print(f"âœ… åˆ›å»ºæ’°å†™æ™ºèƒ½ä½“ï¼šç« èŠ‚ {chapter_id} - {chapter_title}")
            
        return writers
    
    def extract_global_outline_summary(self, enriched_outline: Dict) -> Dict:
        """
        ä»å®Œæ•´çš„enriched_outlineä¸­æå–å…¨å±€æ¦‚è§ˆä¿¡æ¯
        åªä¿ç•™ç« èŠ‚æ ‡é¢˜ã€å­ç« èŠ‚æ ‡é¢˜å’Œcontent_guideï¼Œæ§åˆ¶tokenæ•°é‡
        """
        global_summary = {
            "chapters": {}
        }
        
        chapters = enriched_outline.get("chapters", {})
        
        # å¤„ç†ä¸¤ç§å¯èƒ½çš„æ•°æ®ç»“æ„ï¼šåˆ—è¡¨æˆ–å­—å…¸
        if isinstance(chapters, dict):
            # å¦‚æœchaptersæ˜¯å­—å…¸æ ¼å¼
            for chapter_id, chapter in chapters.items():
                chapter_summary = {
                    "id": chapter.get("id", chapter_id),
                    "title": chapter.get("title", ""),
                    "content_guide": chapter.get("content_guide", ""),
                    "subsections": {}
                }
                
                # æå–å­ç« èŠ‚æ ‡é¢˜
                subsections = chapter.get("subsections", {})
                if isinstance(subsections, dict):
                    for subsection_id, subsection in subsections.items():
                        chapter_summary["subsections"][subsection_id] = {
                            "id": subsection.get("id", subsection_id),
                            "title": subsection.get("title", "")
                        }
                elif isinstance(subsections, list):
                    for subsection in subsections:
                        subsection_id = subsection.get("id", "")
                        if subsection_id:
                            chapter_summary["subsections"][subsection_id] = {
                                "id": subsection_id,
                                "title": subsection.get("title", "")
                            }
                
                global_summary["chapters"][chapter_id] = chapter_summary
                
        elif isinstance(chapters, list):
            # å¦‚æœchaptersæ˜¯åˆ—è¡¨æ ¼å¼
            for chapter in chapters:
                chapter_id = chapter.get("id", "")
                if chapter_id:
                    chapter_summary = {
                        "id": chapter_id,
                        "title": chapter.get("title", ""),
                        "content_guide": chapter.get("content_guide", ""),
                        "subsections": {}
                    }
                    
                    # æå–å­ç« èŠ‚æ ‡é¢˜
                    subsections = chapter.get("subsections", {})
                    if isinstance(subsections, dict):
                        for subsection_id, subsection in subsections.items():
                            chapter_summary["subsections"][subsection_id] = {
                                "id": subsection.get("id", subsection_id),
                                "title": subsection.get("title", "")
                            }
                    elif isinstance(subsections, list):
                        for subsection in subsections:
                            subsection_id = subsection.get("id", "")
                            if subsection_id:
                                chapter_summary["subsections"][subsection_id] = {
                                    "id": subsection_id,
                                    "title": subsection.get("title", "")
                                }
                    
                    global_summary["chapters"][chapter_id] = chapter_summary
        
        return global_summary
    
    async def generate_survey(self, topic: str, subtopics: List[str] = None, output_path: str = None) -> Dict:
        """
        ç”Ÿæˆå®Œæ•´ç»¼è¿°çš„ä¸»æµç¨‹
        
        Args:
            topic: ç»¼è¿°ä¸»é¢˜
            subtopics: å­ä¸»é¢˜åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ç”Ÿæˆçš„ç»¼è¿°ç»“æœ
        """
        # ğŸ†• ç¬¬é›¶é˜¶æ®µï¼šè§£æå’Œæ ‡å‡†åŒ–ç”¨æˆ·è¾“å…¥
        print(f"ğŸ”„ ç¬¬é›¶é˜¶æ®µï¼šè§£æç”¨æˆ·è¯¾é¢˜")
        
        # å…ˆåˆ›å»ºè§£é‡Šå™¨æ™ºèƒ½ä½“
        interpreter_config = AgentConfig(
            model_name=self.config.get("interpreter_model", ModelType.CLAUDE.value),
            temperature=0.3,  # è¾ƒä½çš„æ¸©åº¦ç¡®ä¿æ ‡å‡†åŒ–çš„ä¸€è‡´æ€§
            max_tokens=15000,
            role_description="å­¦æœ¯ä¸»é¢˜è§£é‡Šå’Œæ ‡å‡†åŒ–ä¸“å®¶",
            system_message="ä½ æ˜¯å­¦æœ¯ä¸»é¢˜è§£é‡Šå’Œæ ‡å‡†åŒ–ä¸“å®¶ï¼Œæ“…é•¿å°†ç”¨æˆ·è¾“å…¥è½¬æ¢ä¸ºæ ‡å‡†çš„å­¦æœ¯æ£€ç´¢å…³é”®è¯ã€‚"
        )
        self.interpreter = await self.create_interpreter(interpreter_config)
        
        # æ‰§è¡Œä¸»é¢˜è§£æ
        interpreter_result = await self.interpreter.execute({
            "action": "interpret_topic",
            "topic": topic,
            "subtopics": subtopics or []
        })
        
        if interpreter_result.get("status") != "success":
            print(f"âš ï¸ è¯¾é¢˜è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹è¾“å…¥ç»§ç»­æ‰§è¡Œ")
            standardized_topic = topic
            standardized_subtopics = subtopics or []
        else:
            standardized_topic = interpreter_result.get("standardized_topic")
            standardized_subtopics = interpreter_result.get("standardized_subtopics", [])
            print(f"âœ… è¯¾é¢˜è§£æå®Œæˆï¼š")
            print(f"   æ ‡å‡†åŒ–ä¸»é¢˜: {standardized_topic}")
            print(f"   æ ‡å‡†åŒ–æ¬¡è¦ä¸»é¢˜: {standardized_subtopics}")

        # 1. åˆå§‹åŒ–æ™ºèƒ½ä½“ï¼ˆä½¿ç”¨æ ‡å‡†åŒ–åçš„ä¸»é¢˜ï¼‰
        await self.initialize_agents(standardized_topic, standardized_subtopics)
        
        # 2. ä½¿ç”¨è§„åˆ’æ™ºèƒ½ä½“åˆ›å»ºå¤§çº²ï¼ˆä½¿ç”¨æ ‡å‡†åŒ–åçš„ä¸»é¢˜ï¼‰
        print(f"ğŸ“ ç¬¬ä¸€é˜¶æ®µï¼šåˆ›å»ºç»¼è¿°å¤§çº²")
        planning_result = await self.planner.execute({
            "action": "create_outline",
            "topic": standardized_topic,
            "subtopics": standardized_subtopics
        })
        
        if planning_result.get("status") != "success":
            raise RuntimeError("å¤§çº²åˆ›å»ºå¤±è´¥")
        
        outline = planning_result.get("outline")
        context = planning_result.get("context")
        
        # 3. ä½¿ç”¨ä¸°å¯Œæ™ºèƒ½ä½“ä¸°å¯Œå¤§çº²
        print(f"ğŸ“š ç¬¬äºŒé˜¶æ®µï¼šä¸°å¯Œç»¼è¿°å¤§çº²")
        enrichment_result = await self.enricher.execute({
            "action": "enrich_outline",
            "outline": outline,
            "context": context
        })
        
        if enrichment_result.get("status") != "success":
            raise RuntimeError("å¤§çº²ä¸°å¯Œå¤±è´¥")
        
        enriched_outline = enrichment_result.get("enriched_outline")
        
        # 4. åˆ›å»ºæ’°å†™æ™ºèƒ½ä½“
        writer_config = AgentConfig(
            model_name=self.config.get("writer_model", ModelType.CLAUDE.value),
            temperature=0.7,
            max_tokens=15000,  # éœ€è¦æ›´å¤§çš„ä¸Šä¸‹æ–‡çª—å£æ¥ç”Ÿæˆé•¿å†…å®¹
            role_description="å­¦æœ¯ç»¼è¿°æ’°å†™ä¸“å®¶",
            system_message="ä½ æ˜¯å­¦æœ¯ç»¼è¿°æ’°å†™ä¸“å®¶ï¼Œæ“…é•¿æ ¹æ®ææ–™æ’°å†™ä¸“ä¸šã€æ·±å…¥çš„å­¦æœ¯å†…å®¹ã€‚"
        )
        self.writers = await self.create_writers(enriched_outline, writer_config)
        
        # æå–å…¨å±€æ¦‚è§ˆä¿¡æ¯
        global_outline_summary = self.extract_global_outline_summary(enriched_outline)
        
        # åœ¨generate_surveyæ–¹æ³•ä¸­çš„å¹¶è¡Œæ’°å†™éƒ¨åˆ†
        print(f"âœï¸ ç¬¬ä¸‰é˜¶æ®µï¼šæ’°å†™ç« èŠ‚å†…å®¹ï¼ˆå…± {len(self.writers)} ä¸ªä¸€çº§ç« èŠ‚ï¼Œå¹¶å‘ä¸Šé™ {self.writer_concurrency}ï¼‰")
        semaphore = asyncio.Semaphore(self.writer_concurrency)

        async def run_writer_with_limit(writer_agent: WriterAgent, payload: Dict) -> Dict:
            async with semaphore:
                return await writer_agent.execute(payload)

        chapter_writing_tasks = []
        for chapter_id, writer in self.writers.items():
            # æ‰¾åˆ°å¯¹åº”çš„ç« èŠ‚ä¿¡æ¯
            chapters = enriched_outline.get("chapters", {})
            if isinstance(chapters, dict):
                # å¦‚æœchaptersæ˜¯å­—å…¸ï¼Œç›´æ¥é€šè¿‡é”®è·å–
                chapter_info = chapters.get(chapter_id, {})
            elif isinstance(chapters, list):
                # å¦‚æœchaptersæ˜¯åˆ—è¡¨ï¼Œä½¿ç”¨åŸæ¥çš„æŸ¥æ‰¾æ–¹æ³•
                chapter_info = next((c for c in chapters if c.get("id") == chapter_id), {})
            else:
                chapter_info = {}
            
            if not chapter_info:  # è·³è¿‡æ‰¾ä¸åˆ°å¯¹åº”ç« èŠ‚çš„æ™ºèƒ½ä½“
                print(f"âš ï¸ æœªæ‰¾åˆ°ç« èŠ‚ {chapter_id} çš„ä¿¡æ¯ï¼Œè·³è¿‡")
                continue
            
            payload = {
                "action": "write_section",
                "section_info": chapter_info,
                "main_topic": standardized_topic,
                "subtopics": standardized_subtopics,  # ä½¿ç”¨æ ‡å‡†åŒ–çš„æ¬¡è¦ä¸»é¢˜
                "global_outline_summary": global_outline_summary  # ä¼ é€’å…¨å±€æ¦‚è§ˆä¿¡æ¯
            }

            # åŒ…è£¹å¹¶å‘æ§åˆ¶
            chapter_writing_tasks.append(run_writer_with_limit(writer, payload))

        # ç­‰å¾…æ‰€æœ‰ç« èŠ‚å®Œæˆå†™ä½œï¼ˆå¦‚éœ€æ›´ç¨³å¥ï¼Œå¯ä½¿ç”¨ return_exceptions=Trueï¼‰
        chapter_results = await asyncio.gather(*chapter_writing_tasks)
        
        # å¤„ç†å†™ä½œç»“æœ
        chapter_contents = []
        for result in chapter_results:
            if result.get("status") == "success":
                chapter_contents.append(result.get("result"))
        
        # 6. ä½¿ç”¨è§„åˆ’æ™ºèƒ½ä½“æ•´åˆç»“æœ
        print(f"ğŸ“„ ç¬¬å››é˜¶æ®µï¼šæ•´åˆç»¼è¿°å†…å®¹")
        integration_result = await self.planner.execute({
            "action": "integrate",
            "chapter_contents": chapter_contents,
            "topic": standardized_topic,  # ä½¿ç”¨æ ‡å‡†åŒ–ä¸»é¢˜
            "enriched_outline": enriched_outline,  # ä¼ é€’è¯¦ç»†å¤§çº²ç”¨äºæ‘˜è¦ç”Ÿæˆ
            "subtopics": standardized_subtopics  # ä½¿ç”¨æ ‡å‡†åŒ–æ¬¡è¦ä¸»é¢˜
        })
        
        if integration_result.get("status") != "success":
            raise RuntimeError("å†…å®¹æ•´åˆå¤±è´¥")
        
        final_result = integration_result.get("result")
        
        # ğŸ†• åœ¨ç»“æœä¸­ä¿å­˜åŸå§‹è¾“å…¥å’Œæ ‡å‡†åŒ–ç»“æœ
        final_result["interpretation_info"] = {
            "original_topic": topic,
            "original_subtopics": subtopics or [],
            "standardized_topic": standardized_topic,
            "standardized_subtopics": standardized_subtopics,
            "interpretation_analysis": interpreter_result.get("analysis", "") if interpreter_result.get("status") == "success" else "è§£æå¤±è´¥"
        }
        
        # 7. ä¿å­˜ç»“æœ
        if output_path:
            await self.save_results(final_result, output_path)
        
        print(f"ğŸ‰ ç»¼è¿°ç”Ÿæˆå®Œæˆ: å…± {final_result['statistics']['chapter_count']} ç«  ")
        
        return final_result


    async def save_results(self, survey: Dict, output_path: str):
        """
        ä¿å­˜ç”Ÿæˆç»“æœ
        
        Args:
            survey: ç”Ÿæˆçš„ç»¼è¿°ç»“æœ
            output_path: è¾“å‡ºè·¯å¾„
        """
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # æ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜Markdownæ–‡ä»¶
        md_path = f"{output_path}_{timestamp}.md"
        with open(md_path, "w", encoding="utf-8") as f:
            # å†™å…¥ä¸»æ ‡é¢˜
            f.write(f"# {self.topic}\n\n")
            
            # å¤„ç†æ‘˜è¦éƒ¨åˆ†ï¼Œé¿å…é‡å¤æ ‡é¢˜
            abstract_content = survey.get('abstract', '')
            if abstract_content:
                # æ£€æŸ¥æ‘˜è¦æ˜¯å¦å·²ç»åŒ…å«æ ‡é¢˜
                if abstract_content.strip().startswith("# æ‘˜è¦") or abstract_content.strip().startswith("## æ‘˜è¦"):
                    # æ‘˜è¦å·²åŒ…å«æ ‡é¢˜ï¼Œç›´æ¥å†™å…¥
                    f.write(f"{abstract_content}\n\n")
                else:
                    # æ‘˜è¦æ²¡æœ‰æ ‡é¢˜ï¼Œæ·»åŠ æ ‡é¢˜
                    f.write("# æ‘˜è¦\n\n")
                    f.write(f"{abstract_content}\n\n")
            
            # å†™å…¥å…³é”®è¯
            keywords = survey.get("keywords", [])
            if keywords:
                f.write("**å…³é”®è¯**: " + ", ".join(keywords) + "\n\n")
            
            # å†™å…¥æ­£æ–‡
            f.write(survey.get("full_document", ""))
        
        # ä¿å­˜å…ƒæ•°æ®JSON
        meta_path = f"{output_path}_{timestamp}_meta.json"
        meta_data = {
            "topic": self.topic,
            "subtopics": self.subtopics,
            "timestamp": timestamp,
            "statistics": survey.get("statistics", {}),
            "keywords": survey.get("keywords", [])
        }
        
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(meta_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ ç»¼è¿°å·²ä¿å­˜åˆ°: {md_path}")
        print(f"ğŸ“ å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {meta_path}")
        # ç”ŸæˆWordæ–‡æ¡£
        if DOCX_AVAILABLE:
            word_path = f"{output_path}_{timestamp}.docx"
            
            # æ„å»ºå®Œæ•´çš„æ–‡æ¡£å†…å®¹
            full_content = f"# {self.topic}\n\n"
            
            # æ·»åŠ æ‘˜è¦éƒ¨åˆ†
            if abstract_content:
                if not (abstract_content.strip().startswith("# æ‘˜è¦") or abstract_content.strip().startswith("## æ‘˜è¦")):
                    full_content += "# æ‘˜è¦\n\n"
                full_content += f"{abstract_content}\n\n"
            
            # æ·»åŠ å…³é”®è¯
            if keywords:
                full_content += "**å…³é”®è¯**: " + ", ".join(keywords) + "\n\n"
            
            # æ·»åŠ æ­£æ–‡
            full_content += survey.get("full_document", "")
            
            # è½¬æ¢ä¸ºWordæ–‡æ¡£ï¼ˆä½¿ç”¨æ–°çš„è½¬æ¢å™¨ï¼‰
            success = convert_markdown_to_word(full_content, word_path, self.topic)
            if success:
                print(f"ğŸ“„ Wordæ–‡æ¡£å·²ä¿å­˜åˆ°: {word_path}")
        else:
            print("âš ï¸ æ— æ³•ç”ŸæˆWordæ–‡æ¡£ï¼Œè¯·å®‰è£…python-docx: pip install python-docx")


async def generate_survey(
    topic: str,
    subtopics: List[str] = None,
    output_path: str = None,
    api_key: str = None,
    base_url: str = "https://openrouter.ai/api/v1",
    db_path: str = "./chroma_db",
    models: Dict[str, str] = None,
    log_dir: str = "./logs",
    verbose: bool = True
) -> Dict:
    """
    ç”Ÿæˆå­¦æœ¯ç»¼è¿°çš„ä¾¿æ·å‡½æ•°
    
    å‚æ•°:
        topic: ç»¼è¿°ä¸»é¢˜
        subtopics: å­ä¸»é¢˜åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º'./ma_output/{topic}')
        api_key: APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡OPENROUTER_API_KEYï¼‰
        base_url: APIåŸºç¡€URLï¼ˆé»˜è®¤ä½¿ç”¨OpenRouterï¼‰
        db_path: å‘é‡æ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤ä¸º'./chroma_db'ï¼‰
        models: å„æ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹é…ç½®ï¼ˆå¯é€‰ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        
    è¿”å›:
        ç”Ÿæˆçš„ç»¼è¿°ç»“æœå­—å…¸
    """
    # å‚æ•°æ£€æŸ¥å’Œé»˜è®¤å€¼è®¾ç½®
    if not api_key:
        api_key = os.environ.get("OPENROUTER_API_KEY", "")
        if not api_key:
            raise ValueError("éœ€è¦æä¾›APIå¯†é’¥ï¼ˆé€šè¿‡å‚æ•°æˆ–ç¯å¢ƒå˜é‡OPENROUTER_API_KEYï¼‰")
    
    if not output_path:
        # åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶å
        safe_topic = "".join(c for c in topic if c.isalnum() or c in [' ', '_']).rstrip()
        safe_topic = safe_topic.replace(' ', '_')
        output_path = f"./ma_output/{safe_topic}"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # é»˜è®¤æ¨¡å‹é…ç½®
    if not models:
        models = {
            "interpreter_model": ModelType.CLAUDE.value,  # ğŸ†• æ–°å¢è§£é‡Šå™¨æ¨¡å‹é…ç½®
            "planner_model": ModelType.CLAUDE.value,
            "enricher_model": ModelType.CLAUDE.value,
            "writer_model": ModelType.CLAUDE.value,
        }
    
    if verbose:
        print(f"ğŸ“ ç»¼è¿°ä¸»é¢˜: {topic}")
        print(f"ğŸ“Œ å­ä¸»é¢˜: {', '.join(subtopics) if subtopics else 'æ— '}")
        print(f"ğŸ’¾ è¾“å‡ºè·¯å¾„: {output_path}")
        print(f"ğŸ—„ï¸ æ•°æ®åº“è·¯å¾„: {db_path}")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {models}")
    
    try:
        # åˆå§‹åŒ–LLMå·¥å‚
        llm_factory = LLMFactory(api_key=api_key, base_url=base_url, log_dir=log_dir)
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        db = AcademicPaperDatabase(db_path=db_path)
        
        # åˆ›å»ºå¤šæ™ºèƒ½ä½“åè°ƒå™¨
        coordinator = MultiAgentCoordinator(
            llm_factory=llm_factory,
            db=db,
            config=models
        )
        
        # ç”Ÿæˆç»¼è¿°
        start_time = datetime.now()
        if verbose:
            print(f"â±ï¸ å¼€å§‹ç”Ÿæˆ: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        result = await coordinator.generate_survey(topic, subtopics, output_path)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds() / 60  # è½¬æ¢ä¸ºåˆ†é’Ÿ
        
        if verbose:
            print(f"âœ… ç”Ÿæˆå®Œæˆ: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"â±ï¸ æ€»è€—æ—¶: {duration:.2f} åˆ†é’Ÿ")
            print(f"ğŸ”‘ å…³é”®è¯: {', '.join(result['keywords'])}")
        
        return result
    
    except Exception as e:
        if verbose:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
            traceback.print_exc()
        raise e

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="å¤šæ™ºèƒ½ä½“å­¦æœ¯ç»¼è¿°ç”Ÿæˆç³»ç»Ÿ")
    
    # parser.add_argument("--topic", "-t", type=str, default="Multimodal", help="ç»¼è¿°ä¸»é¢˜")
    # parser.add_argument("--subtopics", "-s", type=str, default="Cross-modal Alignment, Multimodal Reasoning, Efficient Multimodal Training", help="å­ä¸»é¢˜ï¼Œç”¨é€—å·åˆ†éš”")
    parser.add_argument("--topic", "-t", type=str, default="Diffusion Models", help="ç»¼è¿°ä¸»é¢˜")
    parser.add_argument("--subtopics", "-s", type=str, default="image generation, text-to-image, video generation, Image Synthesis, Style Transfer", help="å­ä¸»é¢˜ï¼Œç”¨é€—å·åˆ†éš”")
    parser.add_argument("--output", "-o", type=str, default="./ma_output/", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--api-key", "-k", type=str, default="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", help="OpenRouter APIå¯†é’¥")
    parser.add_argument("--base-url", "-u", type=str, default="https://openrouter.ai/api/v1", help="APIåŸºç¡€URL")
    parser.add_argument("--db-path", "-d", type=str, default="D:/desktop/ZJU/acl300/academic_papers_db", help="å‘é‡æ•°æ®åº“è·¯å¾„")
    parser.add_argument("--interpreter-model", type=str, default=ModelType.GEMINI.value, help="è§£é‡Šå™¨æ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹")  # ğŸ†• æ–°å¢
    parser.add_argument("--planner-model", type=str, default=ModelType.GEMINI.value, help="è§„åˆ’æ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹")
    parser.add_argument("--enricher-model", type=str, default=ModelType.GEMINI.value, help="ä¸°å¯Œæ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹")
    parser.add_argument("--writer-model", type=str, default=ModelType.GEMINI.value, help="æ’°å†™æ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹")
    parser.add_argument("--log-dir", type=str, default="./logs", help="æ—¥å¿—ç›®å½•è·¯å¾„")

    return parser.parse_args()

async def interactive_mode():
    """äº¤äº’æ¨¡å¼ï¼Œé€šè¿‡å‘½ä»¤è¡Œä¸ç”¨æˆ·äº¤äº’"""
    print("=" * 60)
    print("ğŸ“š å¤šæ™ºèƒ½ä½“å­¦æœ¯ç»¼è¿°ç”Ÿæˆç³»ç»Ÿ")
    print("=" * 60)
    
    # æ”¶é›†ç”¨æˆ·è¾“å…¥
    topic = input("è¯·è¾“å…¥ç»¼è¿°ä¸»é¢˜: ").strip()
    if not topic:
        print("âŒ é”™è¯¯: ä¸»é¢˜ä¸èƒ½ä¸ºç©º")
        return
    
    subtopics_input = input("è¯·è¾“å…¥å­ä¸»é¢˜ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¯é€‰ï¼‰: ").strip()
    subtopics = [s.strip() for s in subtopics_input.split(",")] if subtopics_input else []
    
    output_path = input("è¯·è¾“å…¥è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰: ").strip()
    
    api_key = input("è¯·è¾“å…¥APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œç›´æ¥å›è½¦ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰: ").strip()
    
    db_path = input("è¯·è¾“å…¥å‘é‡æ•°æ®åº“è·¯å¾„ï¼ˆå¯é€‰ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰: ").strip()
    if not db_path:
        db_path = "./chroma_db"
    
    # é…ç½®æ¨¡å‹
    print("\né€‰æ‹©æ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹:")
    print("1. Claude (anthropic/claude-sonnet-4)")
    print("2. GPT-4o (openai/gpt-4o)")
    print("3. Gemini (google/gemini-2.5-pro)")
    print("4. Qwen (qwen/qwen2.5-vl-72b-instruct)")
    print("5. DeepSeek (deepseek/deepseek-chat-v3-0324)")
    
    model_map = {
        "1": ModelType.CLAUDE.value,
        "2": ModelType.GPT.value,
        "3": ModelType.GEMINI.value,
        "4": ModelType.QWEN.value,
        "5": ModelType.DS.value
    }
    
    interpreter_model = model_map.get(input("è§£é‡Šå™¨æ™ºèƒ½ä½“æ¨¡å‹ (1-5ï¼Œé»˜è®¤1): ").strip() or "1", ModelType.CLAUDE.value)  # ğŸ†• æ–°å¢
    planner_model = model_map.get(input("è§„åˆ’æ™ºèƒ½ä½“æ¨¡å‹ (1-5ï¼Œé»˜è®¤1): ").strip() or "1", ModelType.CLAUDE.value)
    enricher_model = model_map.get(input("ä¸°å¯Œæ™ºèƒ½ä½“æ¨¡å‹ (1-5ï¼Œé»˜è®¤1): ").strip() or "1", ModelType.CLAUDE.value)
    writer_model = model_map.get(input("æ’°å†™æ™ºèƒ½ä½“æ¨¡å‹ (1-5ï¼Œé»˜è®¤1): ").strip() or "1", ModelType.CLAUDE.value)
    
    models = {
        "interpreter_model": interpreter_model,  # ğŸ†• æ–°å¢
        "planner_model": planner_model,
        "enricher_model": enricher_model,
        "writer_model": writer_model,
    }
    
    # ç¡®è®¤ç”Ÿæˆ
    print("\n" + "=" * 60)
    print(f"ä¸»é¢˜: {topic}")
    print(f"å­ä¸»é¢˜: {', '.join(subtopics) if subtopics else 'æ— '}")
    print(f"è¾“å‡ºè·¯å¾„: {output_path or 'é»˜è®¤'}")
    print(f"æ•°æ®åº“è·¯å¾„: {db_path}")
    print(f"è§£é‡Šå™¨æ¨¡å‹: {interpreter_model}")  # ğŸ†• æ–°å¢
    print(f"è§„åˆ’æ¨¡å‹: {planner_model}")
    print(f"ä¸°å¯Œæ¨¡å‹: {enricher_model}")
    print(f"æ’°å†™æ¨¡å‹: {writer_model}")
    print("=" * 60)
    
    # è®°å½•äº¤äº’å¼€å§‹æ—¶é—´ï¼ˆç”¨äºå–æ¶ˆæ—¶æ˜¾ç¤ºè€—æ—¶ï¼‰
    interaction_start_time = time.time()
    
    confirm = input("\nç¡®è®¤å¼€å§‹ç”Ÿæˆ? (y/n): ").strip().lower()
    if confirm != 'y':
        cancel_time = time.time()
        interaction_duration = cancel_time - interaction_start_time
        print(f"å·²å–æ¶ˆç”Ÿæˆï¼ˆäº¤äº’è€—æ—¶{interaction_duration:.2f}ç§’ï¼‰")
        return
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # å¼€å§‹ç”Ÿæˆ
    try:
        await generate_survey(
            topic=topic,
            subtopics=subtopics if subtopics else None,
            output_path=output_path,
            api_key=api_key,
            db_path=db_path,
            models=models
        )
        
        # è®°å½•ç»“æŸæ—¶é—´å¹¶è®¡ç®—æ€»è€—æ—¶ï¼ˆæ­£å¸¸å®Œæˆï¼‰
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆæ—¶åˆ†ç§’ï¼‰
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = total_time % 60
        
        print(f"\n=== ç»¼è¿°ç”Ÿæˆå®Œæˆ ===")
        print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}")
        print(f"ç»“æŸæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}")
        
        if hours > 0:
            print(f"ç»¼è¿°ç”Ÿæˆè€—æ—¶{hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        elif minutes > 0:
            print(f"ç»¼è¿°ç”Ÿæˆè€—æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        else:
            print(f"ç»¼è¿°ç”Ÿæˆè€—æ—¶{seconds:.2f}ç§’")
            
    except Exception as e:
        # è®°å½•ç»“æŸæ—¶é—´å¹¶è®¡ç®—æ€»è€—æ—¶ï¼ˆå¼‚å¸¸æƒ…å†µï¼‰
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆæ—¶åˆ†ç§’ï¼‰
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = total_time % 60
        
        print(f"\n=== ç»¼è¿°ç”Ÿæˆå¼‚å¸¸ç»“æŸ ===")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}")
        print(f"å¼‚å¸¸æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}")
        
        if hours > 0:
            print(f"è¿è¡Œè€—æ—¶{hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        elif minutes > 0:
            print(f"è¿è¡Œè€—æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        else:
            print(f"è¿è¡Œè€—æ—¶{seconds:.2f}ç§’")
            
        print(f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        traceback.print_exc()

async def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    # å¦‚æœæ²¡æœ‰æä¾›ä¸»é¢˜ï¼Œè¿›å…¥äº¤äº’æ¨¡å¼
    if not args.topic:
        await interactive_mode()
        return
    
    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
    subtopics = [s.strip() for s in args.subtopics.split(",")] if args.subtopics else None
    
    models = {
        "interpreter_model": args.interpreter_model,  # ğŸ†• æ–°å¢
        "planner_model": args.planner_model,
        "enricher_model": args.enricher_model,
        "writer_model": args.writer_model,
    }
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    try:
        await generate_survey(
            topic=args.topic,
            subtopics=subtopics,
            output_path=args.output,
            api_key=args.api_key,
            base_url=args.base_url,
            db_path=args.db_path,
            models=models,
            log_dir=args.log_dir
        )
        
        # è®°å½•ç»“æŸæ—¶é—´å¹¶è®¡ç®—æ€»è€—æ—¶ï¼ˆæ­£å¸¸å®Œæˆï¼‰
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆæ—¶åˆ†ç§’ï¼‰
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = total_time % 60
        
        print(f"\n=== ç»¼è¿°ç”Ÿæˆå®Œæˆ ===")
        print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}")
        print(f"ç»“æŸæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}")
        
        if hours > 0:
            print(f"ç»¼è¿°ç”Ÿæˆè€—æ—¶{hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        elif minutes > 0:
            print(f"ç»¼è¿°ç”Ÿæˆè€—æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        else:
            print(f"ç»¼è¿°ç”Ÿæˆè€—æ—¶{seconds:.2f}ç§’")
            
    except Exception as e:
        # è®°å½•ç»“æŸæ—¶é—´å¹¶è®¡ç®—æ€»è€—æ—¶ï¼ˆå¼‚å¸¸æƒ…å†µï¼‰
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆæ—¶åˆ†ç§’ï¼‰
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = total_time % 60
        
        print(f"\n=== ç»¼è¿°ç”Ÿæˆå¼‚å¸¸ç»“æŸ ===")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}")
        print(f"å¼‚å¸¸æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}")
        
        if hours > 0:
            print(f"è¿è¡Œè€—æ—¶{hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        elif minutes > 0:
            print(f"è¿è¡Œè€—æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        else:
            print(f"è¿è¡Œè€—æ—¶{seconds:.2f}ç§’")
            
        print(f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        traceback.print_exc()
        raise e  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¿æŒåŸæœ‰è¡Œä¸º

if __name__ == "__main__":
    # è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥ï¼Œä»¥æ”¯æŒWindowsä¸Šçš„asyncio
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    asyncio.run(main())