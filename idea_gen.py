# -*- coding: utf-8 -*-
"""
å­¦æœ¯æƒ³æ³•ç”Ÿæˆå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ

è„šæœ¬ç›®æ ‡ä»»åŠ¡ï¼šåŸºäºå·²ç”Ÿæˆçš„ç»¼è¿°æ–‡æ¡£ï¼Œä½¿ç”¨å¤šæ™ºèƒ½ä½“æ¶æ„è‡ªåŠ¨ç”Ÿæˆç ”ç©¶æƒ³æ³•

ä¸Šä¸‹æ–‡ï¼š
- åŸºäºSurvey Genäº§å‡ºçš„markdownæ–‡ä»¶å’Œenriched outline JSONæ–‡ä»¶
- é€šè¿‡å¤šä¸ªä¸“ä¸šæ™ºèƒ½ä½“åä½œå®Œæˆå¤æ‚çš„æƒ³æ³•ç”Ÿæˆä»»åŠ¡
- æ”¯æŒäº¤äº’æ¨¡å¼å’Œå‘½ä»¤è¡Œå‚æ•°æ¨¡å¼ä¸¤ç§è¿è¡Œæ–¹å¼

è¾“å…¥ï¼š
- survey_md_dir: Survey Genäº§å‡ºçš„åŒ…å«å¤šä¸ªmdæ–‡ä»¶çš„ç›®å½•è·¯å¾„
- logs_dir: åŒ…å«LLMè°ƒç”¨æ—¥å¿—çš„ç›®å½•è·¯å¾„ï¼ˆç”¨æ¥æå–enriched_outlineï¼‰
- APIé…ç½®ã€æ¨¡å‹é€‰æ‹©å’Œç”Ÿæˆå‚æ•°
- å‘é‡æ•°æ®åº“è·¯å¾„å’Œè¾“å‡ºè·¯å¾„

æ‰§è¡Œæ­¥éª¤ï¼š
1. ä»æŒ‡å®šç›®å½•æ‰¾åˆ°æœ€æ–°çš„mdå’Œjsonæ–‡ä»¶
2. è§£ææ–‡ä»¶è·å–final_resultå’Œenriched_outlineæ•°æ®
3. åˆå§‹åŒ–LLMå·¥å‚å’Œæ•°æ®åº“è¿æ¥
4. å¯åŠ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼šæ„å»ºæœºä¼šå›¾è°±â†’ç”Ÿæˆideaâ†’è¯„åˆ¤â†’ä¼˜åŒ–
5. ä¿å­˜ç»“æœå¹¶è®°å½•ç”Ÿæˆè€—æ—¶

è¾“å‡ºï¼š
- ç»“æ„åŒ–çš„ç ”ç©¶æƒ³æ³•é›†JSONæ–‡ä»¶
- å¯è¯»çš„æƒ³æ³•æ‘˜è¦Markdownæ–‡ä»¶
- ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯å’Œæ€»è€—æ—¶
"""

import os
import json
import asyncio
import argparse
import glob
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime
import traceback
import sys
from pathlib import Path
import re
import time  # æ·»åŠ æ—¶é—´æ¨¡å—ç”¨äºè®¡æ—¶

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from multi_agent import (
    LLMFactory,
    AcademicPaperDatabase,
    ModelType,
)
from idea_gen_agent import run_idea_generation


# =========================
# åºåˆ—åŒ–å·¥å…·å‡½æ•°
# =========================

def convert_to_serializable(obj: Any) -> Any:
    """é€’å½’è½¬æ¢å¯¹è±¡ä¸ºå¯JSONåºåˆ—åŒ–çš„æ ¼å¼ã€‚"""
    if hasattr(obj, 'to_dict'):
        return obj.to_dict()
    elif isinstance(obj, dict):
        return {key: convert_to_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_serializable(item) for item in obj]
    elif isinstance(obj, (str, int, float, bool, type(None))):
        return obj
    else:
        # å¯¹äºå…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        return str(obj)


# =========================
# æ–‡ä»¶å·¥å…·å‡½æ•°
# =========================

def find_latest_file_by_pattern(directory: str, pattern: str) -> Optional[str]:
    """åœ¨æŒ‡å®šç›®å½•ä¸­æŸ¥æ‰¾ç¬¦åˆæ¨¡å¼çš„æœ€æ–°æ–‡ä»¶
    
    Args:
        directory: ç›®å½•è·¯å¾„
        pattern: æ–‡ä»¶æ¨¡å¼ï¼ˆå¦‚ "*.md", "*_meta.json"ï¼‰
        
    Returns:
        æœ€æ–°æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
    """
    if not os.path.exists(directory):
        print(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {directory}")
        return None
    
    search_pattern = os.path.join(directory, pattern)
    files = glob.glob(search_pattern)
    
    if not files:
        print(f"âš ï¸ åœ¨ç›®å½• {directory} ä¸­æœªæ‰¾åˆ°ç¬¦åˆæ¨¡å¼ {pattern} çš„æ–‡ä»¶")
        return None
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„æ–‡ä»¶
    latest_file = max(files, key=os.path.getmtime)
    print(f"âœ… æ‰¾åˆ°æœ€æ–°æ–‡ä»¶: {latest_file}")
    return latest_file


def find_latest_survey_files(survey_md_dir: str, json_dir: str) -> Tuple[Optional[str], Optional[str]]:
    """æŸ¥æ‰¾æœ€æ–°çš„ç»¼è¿°mdæ–‡ä»¶å’Œenriched outline jsonæ–‡ä»¶
    
    Args:
        survey_md_dir: Survey Genäº§å‡ºçš„mdæ–‡ä»¶ç›®å½•
        json_dir: åŒ…å«JSONæ–‡ä»¶çš„ç›®å½•ï¼ˆå®é™…ä¸Šåº”è¯¥æ˜¯logsç›®å½•ï¼‰
        
    Returns:
        (æœ€æ–°çš„mdæ–‡ä»¶è·¯å¾„, æœ€æ–°çš„LLMè°ƒç”¨æ—¥å¿—æ–‡ä»¶è·¯å¾„)
    """
    print(f"ğŸ” åœ¨ç›®å½•ä¸­æŸ¥æ‰¾æœ€æ–°æ–‡ä»¶...")
    print(f"   Markdownç›®å½•: {survey_md_dir}")
    print(f"   æ—¥å¿—ç›®å½•: {json_dir}")
    
    # æŸ¥æ‰¾æœ€æ–°çš„mdæ–‡ä»¶ï¼ˆæ’é™¤test_å¼€å¤´çš„æ–‡ä»¶ï¼‰
    md_files = []
    if os.path.exists(survey_md_dir):
        for file in glob.glob(os.path.join(survey_md_dir, "*.md")):
            if not os.path.basename(file).startswith("test_"):
                md_files.append(file)
    
    latest_md = max(md_files, key=os.path.getmtime) if md_files else None
    
    # æŸ¥æ‰¾æœ€æ–°çš„LLMè°ƒç”¨æ—¥å¿—æ–‡ä»¶ï¼ˆåŒ…å«enriched outlineä¿¡æ¯ï¼‰
    log_files = []
    possible_log_dirs = [json_dir, "./logs", os.path.join(json_dir, "logs")]
    
    for log_dir in possible_log_dirs:
        if os.path.exists(log_dir):
            for file in glob.glob(os.path.join(log_dir, "llm_calls_*.json")):
                log_files.append(file)
    
    latest_json = max(log_files, key=os.path.getmtime) if log_files else None
    
    if latest_json:
        print(f"âœ… æ‰¾åˆ°æœ€æ–°æ—¥å¿—æ–‡ä»¶: {latest_json}")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°LLMè°ƒç”¨æ—¥å¿—æ–‡ä»¶")
    
    return latest_md, latest_json


def extract_timestamp_from_filename(filename: str) -> Optional[str]:
    """ä»æ–‡ä»¶åä¸­æå–æ—¶é—´æˆ³
    
    Args:
        filename: æ–‡ä»¶å
        
    Returns:
        æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    # åŒ¹é…å½¢å¦‚ YYYYMMDD_HHMMSS çš„æ—¶é—´æˆ³
    pattern = r'(\d{8}_\d{6})'
    match = re.search(pattern, filename)
    return match.group(1) if match else None


# =========================
# æ•°æ®è§£æå‡½æ•°
# =========================

def parse_survey_markdown(md_file_path: str) -> Dict[str, Any]:
    """è§£æç»¼è¿°markdownæ–‡ä»¶ï¼Œæå–final_resultæ ¼å¼çš„æ•°æ®
    
    Args:
        md_file_path: markdownæ–‡ä»¶è·¯å¾„
        
    Returns:
        ç±»ä¼¼äºma_genäº§å‡ºçš„final_resultç»“æ„çš„å­—å…¸
    """
    if not os.path.exists(md_file_path):
        raise FileNotFoundError(f"Markdownæ–‡ä»¶ä¸å­˜åœ¨: {md_file_path}")
    
    print(f"ğŸ“– è§£æç»¼è¿°æ–‡ä»¶: {md_file_path}")
    
    with open(md_file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–åŸºæœ¬ä¿¡æ¯
    lines = content.split('\n')
    title = ""
    abstract = ""
    keywords = []
    
    # è§£ææ ‡é¢˜ï¼ˆç¬¬ä¸€ä¸ª#ï¼‰
    for line in lines:
        if line.strip().startswith('# ') and not title:
            title = line.strip()[2:].strip()
            break
    
    # æŸ¥æ‰¾æ‘˜è¦éƒ¨åˆ†
    in_abstract = False
    abstract_lines = []
    for line in lines:
        if line.strip().startswith('# æ‘˜è¦') or line.strip().startswith('## æ‘˜è¦'):
            in_abstract = True
            continue
        elif line.strip().startswith('#') and in_abstract:
            break
        elif in_abstract and line.strip():
            if line.strip().startswith('**å…³é”®è¯'):
                # æå–å…³é”®è¯
                keywords_text = line.replace('**å…³é”®è¯**:', '').replace('**å…³é”®è¯', '').strip()
                keywords = [k.strip() for k in keywords_text.split(',') if k.strip()]
                break
            else:
                abstract_lines.append(line)
    
    abstract = '\n'.join(abstract_lines).strip()
    
    # æ„å»ºfinal_resultç»“æ„
    final_result = {
        "title": title,
        "abstract": abstract,
        "keywords": keywords,
        "full_document": content,
        "statistics": {
            "word_count": len(content.split()),
            "chapter_count": len([line for line in lines if line.strip().startswith('# ') and not line.startswith('# æ‘˜è¦')]),
            "character_count": len(content)
        },
        "timestamp": extract_timestamp_from_filename(md_file_path) or datetime.now().strftime("%Y%m%d_%H%M%S"),
        "source_file": md_file_path
    }
    
    print(f"âœ… è§£æå®Œæˆ: æ ‡é¢˜='{title}', å…³é”®è¯={len(keywords)}ä¸ª, å­—æ•°={final_result['statistics']['word_count']}")
    return final_result


def parse_enriched_outline_json(json_file_path: str) -> Optional[Dict[str, Any]]:
    """è§£æLLMè°ƒç”¨æ—¥å¿—æ–‡ä»¶ï¼Œæå–enriched outlineæ•°æ®
    
    Args:
        json_file_path: LLMè°ƒç”¨æ—¥å¿—æ–‡ä»¶è·¯å¾„
        
    Returns:
        enriched_outlineæ•°æ®ï¼Œå¦‚æœæ— æ³•è§£æåˆ™è¿”å›None
    """
    if not os.path.exists(json_file_path):
        print(f"âš ï¸ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        return None
    
    print(f"ğŸ“„ è§£æLLMè°ƒç”¨æ—¥å¿—: {json_file_path}")
    
    try:
        enriched_outline = None
        
        # é€è¡Œè¯»å–å¤§æ–‡ä»¶ï¼ŒæŸ¥æ‰¾ç‰¹å®šçš„è®°å½•
        with open(json_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å°è¯•è§£ææ•´ä¸ªJSON
        try:
            data = json.loads(content)
        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯æ ‡å‡†JSONæ ¼å¼ï¼Œå°è¯•æŒ‰è¡Œè§£æ
            print("ğŸ“„ æ–‡ä»¶ä¸æ˜¯æ ‡å‡†JSONæ ¼å¼ï¼Œå°è¯•æŒ‰è¡Œè§£æ...")
            lines = content.strip().split('\n')
            data = []
            for line in lines:
                try:
                    if line.strip():
                        data.append(json.loads(line))
                except json.JSONDecodeError:
                    continue
        
        # ç¡®ä¿dataæ˜¯åˆ—è¡¨æ ¼å¼
        if not isinstance(data, list):
            data = [data] if isinstance(data, dict) else []
        
        # æŸ¥æ‰¾ç¬¦åˆæ¡ä»¶çš„è®°å½•
        for record in data:
            if isinstance(record, dict):
                # æŸ¥æ‰¾agent_nameä¸º"ä¸°å¯Œæ™ºèƒ½ä½“"ä¸”task_typeä¸º"enrichment_final"çš„è®°å½•
                if (record.get("agent_name") == "ä¸°å¯Œæ™ºèƒ½ä½“" and 
                    record.get("task_type") == "enrichment_final"):
                    
                    print(f"âœ… æ‰¾åˆ°ä¸°å¯Œæ™ºèƒ½ä½“çš„enrichment_finalè®°å½•")
                    
                    # æå–parsed_structure
                    parsed_structure = record.get("parsed_structure")
                    if parsed_structure:
                        print(f"âœ… æˆåŠŸæå–enriched_outlineæ•°æ®")
                        return parsed_structure
                    else:
                        # å°è¯•ä»å…¶ä»–å­—æ®µæå–
                        response_data = record.get("response_data", {})
                        if isinstance(response_data, dict) and response_data.get("parsed_structure"):
                            return response_data["parsed_structure"]
                        
                        # å°è¯•ä»resultå­—æ®µæå–
                        result = record.get("result", {})
                        if isinstance(result, dict):
                            if result.get("enriched_outline"):
                                return result["enriched_outline"]
                            elif result.get("parsed_structure"):
                                return result["parsed_structure"]
        
        print(f"âš ï¸ æœªæ‰¾åˆ°ä¸°å¯Œæ™ºèƒ½ä½“çš„enrichment_finalè®°å½•ï¼Œå°†æ„é€ åŸºæœ¬ç»“æ„")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»ä»»ä½•åŒ…å«chaptersçš„è®°å½•ä¸­æå–
        for record in data:
            if isinstance(record, dict):
                # æ£€æŸ¥å„ç§å¯èƒ½çš„å­—æ®µ
                for field in ["parsed_structure", "response_data", "result"]:
                    field_data = record.get(field, {})
                    if isinstance(field_data, dict) and field_data.get("chapters"):
                        print(f"ğŸ”„ ä»{field}å­—æ®µæ‰¾åˆ°ç« èŠ‚æ•°æ®")
                        return field_data
        
        return None
        
    except Exception as e:
        print(f"âŒ æ—¥å¿—æ–‡ä»¶è§£æé”™è¯¯: {e}")
        return None


# =========================
# ä¾¿æ·å…¥å£å‡½æ•°
# =========================

async def generate_ideas(
    survey_md_dir: str,
    logs_dir: str, 
    output_path: str = None,
    api_key: str = None,
    base_url: str = "https://openrouter.ai/api/v1",
    db_path: str = "./chroma_db",
    models: Dict[str, str] = None,
    config: Dict[str, Any] = None,
    log_dir: str = "./logs",
    verbose: bool = True
) -> Dict[str, Any]:
    """
    ç”Ÿæˆç ”ç©¶æƒ³æ³•çš„ä¾¿æ·å‡½æ•°
    
    å‚æ•°:
        survey_md_dir: Survey Genäº§å‡ºçš„mdæ–‡ä»¶ç›®å½•
        logs_dir: LLMè°ƒç”¨æ—¥å¿—ç›®å½•ï¼ˆåŒ…å«enriched outlineæ•°æ®ï¼‰
        output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
        api_key: APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡OPENROUTER_API_KEYï¼‰
        base_url: APIåŸºç¡€URLï¼ˆé»˜è®¤ä½¿ç”¨OpenRouterï¼‰
        db_path: å‘é‡æ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤ä¸º'./chroma_db'ï¼‰
        models: å„æ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹é…ç½®ï¼ˆå¯é€‰ï¼‰
        config: æƒ³æ³•ç”Ÿæˆé…ç½®ï¼ˆå¹¶å‘æ•°ã€é˜ˆå€¼ç­‰ï¼‰
        log_dir: æ—¥å¿—ç›®å½•
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        
    è¿”å›:
        ç”Ÿæˆçš„æƒ³æ³•ç»“æœå­—å…¸
    """
    # å‚æ•°æ£€æŸ¥å’Œé»˜è®¤å€¼è®¾ç½®
    if not api_key:
        api_key = os.environ.get("OPENROUTER_API_KEY", "")
        if not api_key:
            raise ValueError("éœ€è¦æä¾›APIå¯†é’¥ï¼ˆé€šè¿‡å‚æ•°æˆ–ç¯å¢ƒå˜é‡OPENROUTER_API_KEYï¼‰")
    
    # æŸ¥æ‰¾æœ€æ–°æ–‡ä»¶
    latest_md, latest_json = find_latest_survey_files(survey_md_dir, logs_dir)
    
    if not latest_md:
        raise FileNotFoundError(f"åœ¨ç›®å½• {survey_md_dir} ä¸­æœªæ‰¾åˆ°markdownæ–‡ä»¶")
    
    if not latest_json:
        print("âš ï¸ æœªæ‰¾åˆ°JSONæ–‡ä»¶ï¼Œå°†ä½¿ç”¨åŸºæœ¬é…ç½®")
    
    # è§£ææ•°æ®
    final_result = parse_survey_markdown(latest_md)
    enriched_outline = parse_enriched_outline_json(latest_json) if latest_json else None
    
    if not enriched_outline:
        # æ„é€ åŸºæœ¬çš„enriched_outline
        enriched_outline = {
            "topic": final_result.get("title", "æœªçŸ¥ä¸»é¢˜"),
            "chapters": {
                "1": {
                    "id": "1",
                    "title": "å¼•è¨€", 
                    "keywords": final_result.get("keywords", [])[:3],
                    "content_guide": "ç ”ç©¶èƒŒæ™¯ä»‹ç»"
                }
            }
        }
        print("ğŸ”§ ä½¿ç”¨æ„é€ çš„åŸºæœ¬å¤§çº²ç»“æ„")
    
    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if not output_path:
        safe_title = "".join(c for c in final_result.get("title", "ideas") if c.isalnum() or c in [' ', '_']).rstrip()
        safe_title = safe_title.replace(' ', '_')
        output_path = f"./idea_output/{safe_title}"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else output_path, exist_ok=True)
    
    # é»˜è®¤æ¨¡å‹é…ç½®
    if not models:
        models = {
            "miner_model": ModelType.CLAUDE.value,
            "generator_model": ModelType.CLAUDE.value,
            "novelty_critic_model": ModelType.CLAUDE.value,
            "feasibility_critic_model": ModelType.CLAUDE.value,
            "refiner_model": ModelType.CLAUDE.value,
        }
    
    # é»˜è®¤é…ç½®
    if not config:
        config = {
            "idea_concurrency": 6,
            "max_rounds": 3,
            "novelty_threshold": 8.0,
            "feasibility_threshold": 7.0,
            "max_initial_ideas": 6
        }
    
    if verbose:
        print(f"ğŸ“ ç»¼è¿°æ ‡é¢˜: {final_result.get('title')}")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯: {final_result.get('statistics')}")
        print(f"ğŸ’¾ è¾“å‡ºè·¯å¾„: {output_path}")
        print(f"ğŸ—„ï¸ æ•°æ®åº“è·¯å¾„: {db_path}")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {models}")
        print(f"âš™ï¸ é…ç½®å‚æ•°: {config}")
    
    try:
        # åˆå§‹åŒ–LLMå·¥å‚
        llm_factory = LLMFactory(api_key=api_key, base_url=base_url, log_dir=log_dir)
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        db = AcademicPaperDatabase(db_path=db_path)
        
        # ç”Ÿæˆæƒ³æ³•
        start_time = datetime.now()
        if verbose:
            print(f"â±ï¸ å¼€å§‹ç”Ÿæˆ: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # è°ƒç”¨æ ¸å¿ƒæƒ³æ³•ç”Ÿæˆå‡½æ•°
        result = await run_idea_generation(
            final_result=final_result,
            enriched_outline=enriched_outline,
            llm_factory=llm_factory,
            db=db,
            config=config
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds() / 60  # è½¬æ¢ä¸ºåˆ†é’Ÿ
        
        # ä¿å­˜ç»“æœ
        await save_idea_results(result, output_path, final_result.get("title", "ç ”ç©¶æƒ³æ³•"))
        
        if verbose:
            print(f"âœ… ç”Ÿæˆå®Œæˆ: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"â±ï¸ æ€»è€—æ—¶: {duration:.2f} åˆ†é’Ÿ")
            
            # æ˜¾ç¤ºç”Ÿæˆç»“æœç»Ÿè®¡
            if result.get("status") != "failed":
                stats = result.get("statistics", {})
                print(f"ğŸ“ˆ ç”Ÿæˆç»Ÿè®¡:")
                print(f"   - æˆåŠŸç‡: {stats.get('success_rate', 0):.1%}")
                print(f"   - æœ€ç»ˆæƒ³æ³•æ•°: {result.get('final_ideas', {}).get('accepted', {}).get('count', 0)}")
        
        return result
    
    except Exception as e:
        if verbose:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
            traceback.print_exc()
        raise e


async def save_idea_results(result: Dict[str, Any], output_path: str, title: str):
    """
    ä¿å­˜æƒ³æ³•ç”Ÿæˆç»“æœ
    
    Args:
        result: ç”Ÿæˆçš„æƒ³æ³•ç»“æœ
        output_path: è¾“å‡ºè·¯å¾„
        title: æ ‡é¢˜
    """
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else ".", exist_ok=True)
    
    # æ—¶é—´æˆ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜è¯¦ç»†ç»“æœJSON
    result_path = f"{output_path}_{timestamp}_ideas.json"
    
    # è½¬æ¢å¯¹è±¡ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
    serializable_result = convert_to_serializable(result)
    
    with open(result_path, "w", encoding="utf-8") as f:
        json.dump(serializable_result, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜å¯è¯»çš„æƒ³æ³•æ‘˜è¦
    summary_path = f"{output_path}_{timestamp}_summary.md"
    with open(summary_path, "w", encoding="utf-8") as f:
        f.write(f"# {title} - ç ”ç©¶æƒ³æ³•ç”ŸæˆæŠ¥å‘Š\n\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        if result.get("status") == "failed":
            f.write(f"## âŒ ç”Ÿæˆå¤±è´¥\n\n")
            f.write(f"é”™è¯¯ä¿¡æ¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}\n\n")
            return
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = result.get("statistics", {})
        f.write(f"## ğŸ“Š ç”Ÿæˆç»Ÿè®¡\n\n")
        f.write(f"- æˆåŠŸç‡: {stats.get('success_rate', 0):.1%}\n")
        f.write(f"- æ‰§è¡Œæ—¶é—´: {result.get('execution_time_seconds', 0):.2f} ç§’\n\n")
        
        # æœºä¼šå›¾è°±
        opportunity_graph = result.get("opportunity_graph", {})
        f.write(f"## ğŸ—ºï¸ æœºä¼šå›¾è°±\n\n")
        f.write(f"- èŠ‚ç‚¹æ•°: {opportunity_graph.get('node_count', 0)}\n")
        f.write(f"- è¾¹æ•°: {opportunity_graph.get('edge_count', 0)}\n\n")
        
        # æœ€ç»ˆæƒ³æ³•
        final_ideas = result.get("final_ideas", {}).get("accepted", {})
        ideas = final_ideas.get("ideas", [])
        f.write(f"## ğŸ’¡ æœ€ç»ˆæ¥å—çš„æƒ³æ³• ({len(ideas)} ä¸ª)\n\n")
        
        for i, idea in enumerate(ideas, 1):
            # CandidateIdeaæ˜¯dataclassï¼Œç›´æ¥è®¿é—®å±æ€§
            if hasattr(idea, 'title'):
                f.write(f"### {i}. {idea.title}\n\n")
                f.write(f"**æ ¸å¿ƒå‡è®¾**: {idea.core_hypothesis}\n\n")
                f.write(f"**åˆ›æ–°ç‚¹**: {', '.join(idea.initial_innovation_points)}\n\n")
            else:
                # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼ˆå·²è½¬æ¢è¿‡çš„ï¼‰
                f.write(f"### {i}. {idea.get('title', 'æœªå‘½åæƒ³æ³•')}\n\n")
                f.write(f"**æè¿°**: {idea.get('description', 'æ— æè¿°')}\n\n")
                f.write(f"**æ–°é¢–æ€§è¯„åˆ†**: {idea.get('novelty_score', 'N/A')}\n")
                f.write(f"**å¯è¡Œæ€§è¯„åˆ†**: {idea.get('feasibility_score', 'N/A')}\n\n")
                
                if idea.get('rationale'):
                    f.write(f"**è¯„å®¡ç†ç”±**: {idea.get('rationale')}\n\n")
            
            f.write("---\n\n")
    
    print(f"ğŸ“ æƒ³æ³•ç»“æœå·²ä¿å­˜åˆ°: {result_path}")
    print(f"ğŸ“„ æƒ³æ³•æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_path}")


# =========================
# å‘½ä»¤è¡Œæ¥å£
# =========================

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="å¤šæ™ºèƒ½ä½“ç ”ç©¶æƒ³æ³•ç”Ÿæˆç³»ç»Ÿ")
    
    parser.add_argument("--survey-md-dir", "-md", type=str, default="./ma_output/", 
                       help="Survey Genäº§å‡ºçš„markdownæ–‡ä»¶ç›®å½•")
    parser.add_argument("--logs-dir", "-ld", type=str, default="./logs/", 
                       help="LLMè°ƒç”¨æ—¥å¿—ç›®å½•ï¼ˆåŒ…å«enriched outlineæ•°æ®ï¼‰")
    parser.add_argument("--output", "-o", type=str, default="./idea_output/", 
                       help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--api-key", "-k", type=str, 
                       default="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", 
                       help="OpenRouter APIå¯†é’¥")
    parser.add_argument("--base-url", "-u", type=str, default="https://openrouter.ai/api/v1", 
                       help="APIåŸºç¡€URL")
    parser.add_argument("--db-path", "-d", type=str, default="D:/Desktop/ZJU/final_test/db/", 
                       help="å‘é‡æ•°æ®åº“è·¯å¾„")
    
    # æ™ºèƒ½ä½“æ¨¡å‹é…ç½®
    parser.add_argument("--miner-model", type=str, default=ModelType.GEMINI.value, 
                       help="æœºä¼šæŒ–æ˜æ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹")
    parser.add_argument("--generator-model", type=str, default=ModelType.GEMINI.value, 
                       help="æƒ³æ³•ç”Ÿæˆæ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹")
    parser.add_argument("--novelty-critic-model", type=str, default=ModelType.GEMINI.value, 
                       help="æ–°é¢–æ€§è¯„å®¡æ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹")
    parser.add_argument("--feasibility-critic-model", type=str, default=ModelType.GEMINI.value, 
                       help="å¯è¡Œæ€§è¯„å®¡æ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹")
    parser.add_argument("--refiner-model", type=str, default=ModelType.GEMINI.value, 
                       help="æƒ³æ³•ç²¾ç‚¼æ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹")
    
    # æƒ³æ³•ç”Ÿæˆé…ç½®
    parser.add_argument("--idea-concurrency", type=int, default=6, 
                       help="æƒ³æ³•ç”Ÿæˆå¹¶å‘æ•°")
    parser.add_argument("--max-rounds", type=int, default=2, 
                       help="æœ€å¤§è¿­ä»£è½®æ•°")
    parser.add_argument("--novelty-threshold", type=float, default=8.0, 
                       help="æ–°é¢–æ€§é˜ˆå€¼")
    parser.add_argument("--feasibility-threshold", type=float, default=7.0, 
                       help="å¯è¡Œæ€§é˜ˆå€¼")
    parser.add_argument("--max-initial-ideas", type=int, default=50, 
                       help="åˆå§‹æƒ³æ³•ç”Ÿæˆæ•°é‡")
    
    parser.add_argument("--log-dir", type=str, default="./logs", help="æ—¥å¿—ç›®å½•è·¯å¾„")

    return parser.parse_args()


async def interactive_mode():
    """äº¤äº’æ¨¡å¼ï¼Œé€šè¿‡å‘½ä»¤è¡Œä¸ç”¨æˆ·äº¤äº’"""
    print("=" * 60)
    print("ğŸ’¡ å¤šæ™ºèƒ½ä½“ç ”ç©¶æƒ³æ³•ç”Ÿæˆç³»ç»Ÿ")
    print("=" * 60)
    
    # æ”¶é›†ç”¨æˆ·è¾“å…¥
    survey_md_dir = input("è¯·è¾“å…¥Survey Genäº§å‡ºçš„Markdownæ–‡ä»¶ç›®å½•è·¯å¾„: ").strip()
    if not survey_md_dir:
        survey_md_dir = "./ma_output/"
    
    logs_dir = input("è¯·è¾“å…¥LLMè°ƒç”¨æ—¥å¿—ç›®å½•è·¯å¾„ï¼ˆåŒ…å«enriched outlineæ•°æ®ï¼‰: ").strip()
    if not logs_dir:
        logs_dir = "./logs/"  # é»˜è®¤logsç›®å½•
    
    output_path = input("è¯·è¾“å…¥è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰: ").strip()
    
    api_key = input("è¯·è¾“å…¥APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œç›´æ¥å›è½¦ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰: ").strip()
    
    db_path = input("è¯·è¾“å…¥å‘é‡æ•°æ®åº“è·¯å¾„ï¼ˆå¯é€‰ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰: ").strip()
    if not db_path:
        db_path = "./chroma_db"
    
    # é…ç½®æ¨¡å‹
    print("\né€‰æ‹©æ™ºèƒ½ä½“ä½¿ç”¨çš„æ¨¡å‹:")
    print("1. Claude (anthropic/claude-sonnet-4)")
    print("2. GPT-4o (openai/gpt-4o)")
    print("3. Gemini (google/gemini-2.5-flash)")
    print("4. Qwen (qwen/qwen2.5-vl-72b-instruct)")
    print("5. DeepSeek (deepseek/deepseek-chat-v3-0324)")
    
    model_map = {
        "1": ModelType.CLAUDE.value,
        "2": ModelType.GPT.value,
        "3": ModelType.GEMINI.value,
        "4": ModelType.QWEN.value,
        "5": ModelType.DS.value
    }
    
    miner_model = model_map.get(input("æœºä¼šæŒ–æ˜æ™ºèƒ½ä½“æ¨¡å‹ (1-5ï¼Œé»˜è®¤1): ").strip() or "1", ModelType.CLAUDE.value)
    generator_model = model_map.get(input("æƒ³æ³•ç”Ÿæˆæ™ºèƒ½ä½“æ¨¡å‹ (1-5ï¼Œé»˜è®¤1): ").strip() or "1", ModelType.CLAUDE.value)
    novelty_critic_model = model_map.get(input("æ–°é¢–æ€§è¯„å®¡æ™ºèƒ½ä½“æ¨¡å‹ (1-5ï¼Œé»˜è®¤1): ").strip() or "1", ModelType.CLAUDE.value)
    feasibility_critic_model = model_map.get(input("å¯è¡Œæ€§è¯„å®¡æ™ºèƒ½ä½“æ¨¡å‹ (1-5ï¼Œé»˜è®¤1): ").strip() or "1", ModelType.CLAUDE.value)
    refiner_model = model_map.get(input("æƒ³æ³•ç²¾ç‚¼æ™ºèƒ½ä½“æ¨¡å‹ (1-5ï¼Œé»˜è®¤1): ").strip() or "1", ModelType.CLAUDE.value)
    
    models = {
        "miner_model": miner_model,
        "generator_model": generator_model,
        "novelty_critic_model": novelty_critic_model,
        "feasibility_critic_model": feasibility_critic_model,
        "refiner_model": refiner_model,
    }
    
    # é…ç½®å‚æ•°
    print("\né…ç½®æƒ³æ³•ç”Ÿæˆå‚æ•°:")
    idea_concurrency = int(input("æƒ³æ³•ç”Ÿæˆå¹¶å‘æ•° (é»˜è®¤6): ").strip() or "6")
    max_rounds = int(input("æœ€å¤§è¿­ä»£è½®æ•° (é»˜è®¤3): ").strip() or "3")
    novelty_threshold = float(input("æ–°é¢–æ€§é˜ˆå€¼ (é»˜è®¤8.0): ").strip() or "8.0")
    feasibility_threshold = float(input("å¯è¡Œæ€§é˜ˆå€¼ (é»˜è®¤7.0): ").strip() or "7.0")
    max_initial_ideas = int(input("åˆå§‹æƒ³æ³•ç”Ÿæˆæ•°é‡ (é»˜è®¤6): ").strip() or "6")
    
    config = {
        "idea_concurrency": idea_concurrency,
        "max_rounds": max_rounds,
        "novelty_threshold": novelty_threshold,
        "feasibility_threshold": feasibility_threshold,
        "max_initial_ideas": max_initial_ideas
    }
    
    # ç¡®è®¤ç”Ÿæˆ
    print("\n" + "=" * 60)
    print(f"Markdownç›®å½•: {survey_md_dir}")
    print(f"æ—¥å¿—ç›®å½•: {logs_dir}")
    print(f"è¾“å‡ºè·¯å¾„: {output_path or 'é»˜è®¤'}")
    print(f"æ•°æ®åº“è·¯å¾„: {db_path}")
    print(f"æœºä¼šæŒ–æ˜æ¨¡å‹: {miner_model}")
    print(f"æƒ³æ³•ç”Ÿæˆæ¨¡å‹: {generator_model}")
    print(f"æ–°é¢–æ€§è¯„å®¡æ¨¡å‹: {novelty_critic_model}")
    print(f"å¯è¡Œæ€§è¯„å®¡æ¨¡å‹: {feasibility_critic_model}")
    print(f"æƒ³æ³•ç²¾ç‚¼æ¨¡å‹: {refiner_model}")
    print(f"é…ç½®å‚æ•°: {config}")
    print("=" * 60)
    
    # è®°å½•äº¤äº’å¼€å§‹æ—¶é—´ï¼ˆç”¨äºå–æ¶ˆæ—¶æ˜¾ç¤ºè€—æ—¶ï¼‰
    interaction_start_time = time.time()
    
    confirm = input("\nç¡®è®¤å¼€å§‹ç”Ÿæˆ? (y/n): ").strip().lower()
    if confirm != 'y':
        cancel_time = time.time()
        interaction_duration = cancel_time - interaction_start_time
        print(f"å·²å–æ¶ˆç”Ÿæˆï¼ˆäº¤äº’è€—æ—¶{interaction_duration:.2f}ç§’ï¼‰")
        return
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # å¼€å§‹ç”Ÿæˆ
    try:
        await generate_ideas(
            survey_md_dir=survey_md_dir,
            logs_dir=logs_dir,
            output_path=output_path,
            api_key=api_key,
            db_path=db_path,
            models=models,
            config=config
        )
        
        # è®°å½•ç»“æŸæ—¶é—´å¹¶è®¡ç®—æ€»è€—æ—¶ï¼ˆæ­£å¸¸å®Œæˆï¼‰
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆæ—¶åˆ†ç§’ï¼‰
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = total_time % 60
        
        print(f"\n=== æƒ³æ³•ç”Ÿæˆå®Œæˆ ===")
        print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}")
        print(f"ç»“æŸæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}")
        
        if hours > 0:
            print(f"ç”Ÿæˆideaè€—æ—¶{hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        elif minutes > 0:
            print(f"ç”Ÿæˆideaè€—æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        else:
            print(f"ç”Ÿæˆideaè€—æ—¶{seconds:.2f}ç§’")
            
    except Exception as e:
        # è®°å½•ç»“æŸæ—¶é—´å¹¶è®¡ç®—æ€»è€—æ—¶ï¼ˆå¼‚å¸¸æƒ…å†µï¼‰
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆæ—¶åˆ†ç§’ï¼‰
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = total_time % 60
        
        print(f"\n=== æƒ³æ³•ç”Ÿæˆå¼‚å¸¸ç»“æŸ ===")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}")
        print(f"å¼‚å¸¸æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}")
        
        if hours > 0:
            print(f"è¿è¡Œè€—æ—¶{hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        elif minutes > 0:
            print(f"è¿è¡Œè€—æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        else:
            print(f"è¿è¡Œè€—æ—¶{seconds:.2f}ç§’")
            
        print(f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        traceback.print_exc()


async def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    # å¦‚æœæ²¡æœ‰æä¾›markdownç›®å½•ï¼Œè¿›å…¥äº¤äº’æ¨¡å¼
    if not args.survey_md_dir or args.survey_md_dir == "./ma_output/":
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨é»˜è®¤ç›®å½•
        if not os.path.exists(args.survey_md_dir):
            await interactive_mode()
            return
    
    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
    models = {
        "miner_model": args.miner_model,
        "generator_model": args.generator_model,
        "novelty_critic_model": args.novelty_critic_model,
        "feasibility_critic_model": args.feasibility_critic_model,
        "refiner_model": args.refiner_model,
    }
    
    config = {
        "idea_concurrency": args.idea_concurrency,
        "max_rounds": args.max_rounds,
        "novelty_threshold": args.novelty_threshold,
        "feasibility_threshold": args.feasibility_threshold,
        "max_initial_ideas": args.max_initial_ideas
    }
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    try:
        await generate_ideas(
            survey_md_dir=args.survey_md_dir,
            logs_dir=args.logs_dir,
            output_path=args.output,
            api_key=args.api_key,
            base_url=args.base_url,
            db_path=args.db_path,
            models=models,
            config=config,
            log_dir=args.log_dir
        )
        
        # è®°å½•ç»“æŸæ—¶é—´å¹¶è®¡ç®—æ€»è€—æ—¶ï¼ˆæ­£å¸¸å®Œæˆï¼‰
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆæ—¶åˆ†ç§’ï¼‰
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = total_time % 60
        
        print(f"\n=== æƒ³æ³•ç”Ÿæˆå®Œæˆ ===")
        print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}")
        print(f"ç»“æŸæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}")
        
        if hours > 0:
            print(f"ç”Ÿæˆideaè€—æ—¶{hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        elif minutes > 0:
            print(f"ç”Ÿæˆideaè€—æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        else:
            print(f"ç”Ÿæˆideaè€—æ—¶{seconds:.2f}ç§’")
            
    except Exception as e:
        # è®°å½•ç»“æŸæ—¶é—´å¹¶è®¡ç®—æ€»è€—æ—¶ï¼ˆå¼‚å¸¸æƒ…å†µï¼‰
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆæ—¶åˆ†ç§’ï¼‰
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = total_time % 60
        
        print(f"\n=== æƒ³æ³•ç”Ÿæˆå¼‚å¸¸ç»“æŸ ===")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}")
        print(f"å¼‚å¸¸æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}")
        
        if hours > 0:
            print(f"è¿è¡Œè€—æ—¶{hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        elif minutes > 0:
            print(f"è¿è¡Œè€—æ—¶{minutes}åˆ†é’Ÿ{seconds:.2f}ç§’")
        else:
            print(f"è¿è¡Œè€—æ—¶{seconds:.2f}ç§’")
            
        print(f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        traceback.print_exc()
        raise e  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¿æŒåŸæœ‰è¡Œä¸º


if __name__ == "__main__":
    # è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥ï¼Œä»¥æ”¯æŒWindowsä¸Šçš„asyncio
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    asyncio.run(main())